{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 . Write a python program to display all the header tags from‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\users\\admin\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1 class=\"firstHeading\" id=\"firstHeading\">Main Page</h1>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>,\n",
       " <h2>Navigation menu</h2>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-personal-label\">\n",
       " <span>Personal tools</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-namespaces-label\">\n",
       " <span>Namespaces</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-variants-label\">\n",
       " <span>Variants</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-views-label\">\n",
       " <span>Views</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-cactions-label\">\n",
       " <span>More</span>\n",
       " </h3>,\n",
       " <h3>\n",
       " <label for=\"searchInput\">Search</label>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-navigation-label\">\n",
       " <span>Navigation</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-interaction-label\">\n",
       " <span>Contribute</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-tb-label\">\n",
       " <span>Tools</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-coll-print_export-label\">\n",
       " <span>Print/export</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-wikibase-otherprojects-label\">\n",
       " <span>In other projects</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-lang-label\">\n",
       " <span>Languages</span>\n",
       " </h3>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headings = soup.find_all(['h1', 'h2', 'h3','h4','h5','h6'])\n",
    "headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Main Page',\n",
       " \"From today's featured article\",\n",
       " 'Did you know\\xa0...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages',\n",
       " 'Navigation menu',\n",
       " 'Personal tools',\n",
       " 'Namespaces',\n",
       " 'Variants',\n",
       " 'Views',\n",
       " 'More',\n",
       " 'Search',\n",
       " 'Navigation',\n",
       " 'Contribute',\n",
       " 'Tools',\n",
       " 'Print/export',\n",
       " 'In other projects',\n",
       " 'Languages']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_headings = []\n",
    "for i in headings:\n",
    "    main_headings.append(i.text.replace('\\n',''))\n",
    "main_headings\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "page1 = requests.get('https://www.imdb.com/list/ls091520106/')\n",
    "soup = BeautifulSoup(page1.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Shawshank Redemption',\n",
       " 'The Godfather',\n",
       " 'The Godfather: Part II',\n",
       " 'The Dark Knight',\n",
       " '12 Angry Men',\n",
       " \"Schindler's List\",\n",
       " 'The Lord of the Rings: The Return of the King',\n",
       " 'Pulp Fiction',\n",
       " 'Il buono, il brutto, il cattivo',\n",
       " 'Fight Club',\n",
       " 'Joker',\n",
       " 'The Lord of the Rings: The Fellowship of the Ring',\n",
       " 'Forrest Gump',\n",
       " 'Inception',\n",
       " 'Star Wars: Episode V - The Empire Strikes Back',\n",
       " 'The Lord of the Rings: The Two Towers',\n",
       " 'The Matrix',\n",
       " \"One Flew Over the Cuckoo's Nest\",\n",
       " 'Goodfellas',\n",
       " 'Shichinin no samurai',\n",
       " 'Se7en',\n",
       " 'Cidade de Deus',\n",
       " 'La vita è bella',\n",
       " 'The Silence of the Lambs',\n",
       " 'Star Wars',\n",
       " \"It's a Wonderful Life\",\n",
       " 'Saving Private Ryan',\n",
       " 'Sen to Chihiro no kamikakushi',\n",
       " 'The Green Mile',\n",
       " 'Léon',\n",
       " 'Seppuku',\n",
       " 'Interstellar',\n",
       " 'The Usual Suspects',\n",
       " 'The Lion King',\n",
       " 'American History X',\n",
       " 'Back to the Future',\n",
       " 'The Pianist',\n",
       " 'Modern Times',\n",
       " 'Terminator 2: Judgment Day',\n",
       " 'The Intouchables',\n",
       " 'Psycho',\n",
       " 'Gladiator',\n",
       " 'City Lights',\n",
       " 'The Departed',\n",
       " 'Whiplash',\n",
       " 'Once Upon a Time in the West',\n",
       " 'The Prestige',\n",
       " 'Avengers: Endgame',\n",
       " 'Casablanca',\n",
       " 'Hotaru no haka',\n",
       " 'Rear Window',\n",
       " 'Nuovo Cinema Paradiso',\n",
       " 'Alien',\n",
       " 'Raiders of the Lost Ark',\n",
       " 'Memento',\n",
       " 'Apocalypse Now',\n",
       " 'The Great Dictator',\n",
       " 'The Lives of Others',\n",
       " 'Avengers: Infinity War',\n",
       " 'Django Unchained',\n",
       " 'Spider-Man: Into the Spider-Verse',\n",
       " 'The Shining',\n",
       " 'Paths of Glory',\n",
       " 'WALL·E',\n",
       " 'Sunset Blvd.',\n",
       " 'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb',\n",
       " 'Mononoke-hime',\n",
       " 'Oldeuboi',\n",
       " 'Witness for the Prosecution',\n",
       " 'The Dark Knight Rises',\n",
       " 'Once Upon a Time in America',\n",
       " 'Gisaengchung',\n",
       " 'Aliens',\n",
       " 'American Beauty',\n",
       " 'Coco',\n",
       " 'Kimi no na wa.',\n",
       " 'Braveheart',\n",
       " 'Das Boot',\n",
       " '3 Idiots',\n",
       " 'Taare Zameen Par',\n",
       " 'Star Wars: Episode VI - Return of the Jedi',\n",
       " 'Toy Story',\n",
       " 'Reservoir Dogs',\n",
       " 'Amadeus',\n",
       " 'Dangal',\n",
       " 'Good Will Hunting',\n",
       " 'Inglourious Basterds',\n",
       " 'M - Eine Stadt sucht einen Mörder',\n",
       " 'Requiem for a Dream',\n",
       " '2001: A Space Odyssey',\n",
       " 'Vertigo',\n",
       " 'Eternal Sunshine of the Spotless Mind',\n",
       " 'Citizen Kane',\n",
       " 'Full Metal Jacket',\n",
       " 'Jagten',\n",
       " 'North by Northwest',\n",
       " 'A Clockwork Orange',\n",
       " 'Snatch',\n",
       " \"Le fabuleux destin d'Amélie Poulain\",\n",
       " 'The Kid']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = soup.find_all('h3', class_ =\"lister-item-header\")\n",
    "movie_titles = []\n",
    "for i in movies:\n",
    "    for j in i.find_all('a'):\n",
    "        movie_titles.append(j.text.replace('\\n',''))\n",
    "movie_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.3',\n",
       " '9.2',\n",
       " '9',\n",
       " '9',\n",
       " '9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.4',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.4',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.6',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = soup.find_all('div',class_=\"ipl-rating-star small\")\n",
    "Ratings = []\n",
    "\n",
    "for i in ratings:\n",
    "    Ratings.append(i.text.replace('\\n',''))\n",
    "Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1994)',\n",
       " '(1972)',\n",
       " '(1974)',\n",
       " '(2008)',\n",
       " '(1957)',\n",
       " '(1993)',\n",
       " '(2003)',\n",
       " '(1994)',\n",
       " '(1966)',\n",
       " '(1999)',\n",
       " '(2019)',\n",
       " '(2001)',\n",
       " '(1994)',\n",
       " '(2010)',\n",
       " '(1980)',\n",
       " '(2002)',\n",
       " '(1999)',\n",
       " '(1975)',\n",
       " '(1990)',\n",
       " '(1954)',\n",
       " '(1995)',\n",
       " '(2002)',\n",
       " '(1997)',\n",
       " '(1991)',\n",
       " '(1977)',\n",
       " '(1946)',\n",
       " '(1998)',\n",
       " '(2001)',\n",
       " '(1999)',\n",
       " '(1994)',\n",
       " '(1962)',\n",
       " '(2014)',\n",
       " '(1995)',\n",
       " '(1994)',\n",
       " '(1998)',\n",
       " '(1985)',\n",
       " '(2002)',\n",
       " '(1936)',\n",
       " '(1991)',\n",
       " '(2011)',\n",
       " '(1960)',\n",
       " '(2000)',\n",
       " '(1931)',\n",
       " '(2006)',\n",
       " '(2014)',\n",
       " '(1968)',\n",
       " '(2006)',\n",
       " '(2019)',\n",
       " '(1942)',\n",
       " '(1988)',\n",
       " '(1954)',\n",
       " '(1988)',\n",
       " '(1979)',\n",
       " '(1981)',\n",
       " '(2000)',\n",
       " '(1979)',\n",
       " '(1940)',\n",
       " '(2006)',\n",
       " '(2018)',\n",
       " '(2012)',\n",
       " '(2018)',\n",
       " '(1980)',\n",
       " '(1957)',\n",
       " '(2008)',\n",
       " '(1950)',\n",
       " '(1964)',\n",
       " '(1997)',\n",
       " '(2003)',\n",
       " '(1957)',\n",
       " '(2012)',\n",
       " '(1984)',\n",
       " '(2019)',\n",
       " '(1986)',\n",
       " '(1999)',\n",
       " '(I) (2017)',\n",
       " '(2016)',\n",
       " '(1995)',\n",
       " '(1981)',\n",
       " '(2009)',\n",
       " '(2007)',\n",
       " '(1983)',\n",
       " '(1995)',\n",
       " '(1992)',\n",
       " '(1984)',\n",
       " '(2016)',\n",
       " '(1997)',\n",
       " '(2009)',\n",
       " '(1931)',\n",
       " '(2000)',\n",
       " '(1968)',\n",
       " '(1958)',\n",
       " '(2004)',\n",
       " '(1941)',\n",
       " '(1987)',\n",
       " '(2012)',\n",
       " '(1959)',\n",
       " '(1971)',\n",
       " '(2000)',\n",
       " '(2001)',\n",
       " '(1921)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "release_year = soup.find_all('h3',class_ = 'lister-item-header')\n",
    "Y_O_R = []\n",
    "\n",
    "for i in release_year:\n",
    "    for j in i.find_all('span' , class_ = 'lister-item-year text-muted unbold'):\n",
    "        Y_O_R.append(j.text.replace('\\n',''))\n",
    "Y_O_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Names</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>9</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1971)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Snatch</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Le fabuleux destin d'Amélie Poulain</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Kid</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1921)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Movie Names Rating Year of Release\n",
       "0              The Shawshank Redemption    9.3          (1994)\n",
       "1                         The Godfather    9.2          (1972)\n",
       "2                The Godfather: Part II      9          (1974)\n",
       "3                       The Dark Knight      9          (2008)\n",
       "4                          12 Angry Men      9          (1957)\n",
       "..                                  ...    ...             ...\n",
       "95                   North by Northwest    8.3          (1959)\n",
       "96                   A Clockwork Orange    8.3          (1971)\n",
       "97                               Snatch    8.3          (2000)\n",
       "98  Le fabuleux destin d'Amélie Poulain    8.3          (2001)\n",
       "99                              The Kid    8.3          (1921)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame()\n",
    "data['Movie Names'] = movie_titles\n",
    "data['Rating'] = Ratings\n",
    "data['Year of Release'] = Y_O_R\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q.3 Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "page3 = requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "soup = BeautifulSoup(page3.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = soup.find_all('td',class_ = \"titleColumn\")\n",
    "rating = soup.find_all('td',class_ = 'ratingColumn imdbRating')\n",
    "release = soup.find_all('td',class_ = 'titleColumn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.      Nayakan(1987)',\n",
       " '2.      Pariyerum Perumal(2018)',\n",
       " '3.      Anbe Sivam(2003)',\n",
       " '4.      C/o Kancharapalem(2018)',\n",
       " '5.      Golmaal(1979)',\n",
       " '6.      Apur Sansar(1959)',\n",
       " '7.      Pather Panchali(1955)',\n",
       " '8.      Manichitrathazhu(1993)',\n",
       " '9.      Kireedam(1989)',\n",
       " '10.      Natsamrat(2016)',\n",
       " '11.      96(2018)',\n",
       " '12.      Thevar Magan(1992)',\n",
       " '13.      Black Friday(2004)',\n",
       " '14.      Kumbalangi Nights(2019)',\n",
       " '15.      Visaaranai(2015)',\n",
       " '16.      3 Idiots(2009)',\n",
       " '17.      Drishyam 2(2021)',\n",
       " '18.      Soorarai Pottru(2020)',\n",
       " '19.      Jersey(2019)',\n",
       " '20.      Taare Zameen Par(2007)',\n",
       " '21.      Thalapathi(1991)',\n",
       " '22.      Asuran(2019)',\n",
       " '23.      Sarpatta Parambarai(2021)',\n",
       " '24.      Dangal(2016)',\n",
       " '25.      Kaithi(2019)',\n",
       " '26.      Ratsasan(2018)',\n",
       " '27.      Devasuram(1993)',\n",
       " '28.      Aparajito(1956)',\n",
       " '29.      Jaane Bhi Do Yaaro(1983)',\n",
       " '30.      Pyaasa(1957)',\n",
       " '31.      Vada Chennai(2018)',\n",
       " '32.      Peranbu(2018)',\n",
       " '33.      Guide(1965)',\n",
       " '34.      Thani Oruvan(2015)',\n",
       " '35.      Kannathil Muthamittal(2002)',\n",
       " '36.      Iruvar(1997)',\n",
       " '37.      Chupke Chupke(1975)',\n",
       " '38.      Spadikam(1995)',\n",
       " '39.      Agent Sai Srinivasa Athreya(2019)',\n",
       " '40.      Super Deluxe(2019)',\n",
       " '41.      Mahanati(2018)',\n",
       " '42.      Drishyam(2013)',\n",
       " '43.      Aruvi(2016)',\n",
       " '44.      Vikram Vedha(2017)',\n",
       " '45.      Khosla Ka Ghosla!(2006)',\n",
       " '46.      Tumbbad(2018)',\n",
       " '47.      Pudhu Pettai(2006)',\n",
       " '48.      Premam(2015)',\n",
       " '49.      Anniyan(2005)',\n",
       " '50.      Anand(1971)',\n",
       " '51.      Kaakkaa Muttai(2014)',\n",
       " '52.      Bangalore Days(2014)',\n",
       " '53.      Mudhalvan(1999)',\n",
       " '54.      Dhuruvangal Pathinaaru(2016)',\n",
       " '55.      Satya(1998)',\n",
       " '56.      Andhadhun(2018)',\n",
       " '57.      Papanasam(2015)',\n",
       " '58.      Soodhu Kavvum(2013)',\n",
       " '59.      Shahid(2012)',\n",
       " '60.      Jigarthanda(2014)',\n",
       " '61.      Gangs of Wasseypur(2012)',\n",
       " '62.      Pithamagan(2003)',\n",
       " '63.      Paan Singh Tomar(2012)',\n",
       " '64.      Bhaag Milkha Bhaag(2013)',\n",
       " '65.      Hera Pheri(2000)',\n",
       " '66.      Sairat(2016)',\n",
       " '67.      Talvar(2015)',\n",
       " '68.      Sholay(1975)',\n",
       " '69.      Swades: We, the People(2004)',\n",
       " '70.      Chak De! India(2007)',\n",
       " '71.      Ustad Hotel(2012)',\n",
       " '72.      Black(2005)',\n",
       " '73.      Drishyam(2015)',\n",
       " '74.      Zindagi Na Milegi Dobara(2011)',\n",
       " '75.      Jo Jeeta Wohi Sikandar(1992)',\n",
       " '76.      Maheshinte Prathikaaram(2016)',\n",
       " '77.      Mughal-E-Azam(1960)',\n",
       " '78.      Nil Battey Sannata(2015)',\n",
       " '79.      Charulata(1964)',\n",
       " '80.      Udaan(2010)',\n",
       " '81.      Theeran adhigaaram ondru(2017)',\n",
       " '82.      Article 15(2019)',\n",
       " '83.      A Wednesday(2008)',\n",
       " '84.      Queen(2013)',\n",
       " '85.      Masaan(2015)',\n",
       " '86.      Munna Bhai M.B.B.S.(2003)',\n",
       " '87.      Alai Payuthey(2000)',\n",
       " '88.      Sarfarosh(1999)',\n",
       " '89.      Baasha(1995)',\n",
       " '90.      Dil Chahta Hai(2001)',\n",
       " '91.      Chhichhore(2019)',\n",
       " '92.      OMG: Oh My God!(2012)',\n",
       " '93.      Roja(1992)',\n",
       " '94.      Rang De Basanti(2006)',\n",
       " '95.      Virumandi(2004)',\n",
       " '96.      Andaz Apna Apna(1994)',\n",
       " '97.      Lagaan: Once Upon a Time in India(2001)',\n",
       " '98.      Kahaani(2012)',\n",
       " '99.      Uri: The Surgical Strike(2018)',\n",
       " '100.      PK(2014)']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Movies = []\n",
    "\n",
    "for i in movie[:100]:\n",
    "    for j in i.find_all('a'):\n",
    "        Movies.append(i.text.strip().replace('\\n',''))\n",
    "Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ratings = []\n",
    "\n",
    "for i in rating[:100]:\n",
    "    Ratings.append(i.text.replace('\\n',''))\n",
    "Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1987)',\n",
       " '(2018)',\n",
       " '(2003)',\n",
       " '(2018)',\n",
       " '(1979)',\n",
       " '(1959)',\n",
       " '(1955)',\n",
       " '(1993)',\n",
       " '(1989)',\n",
       " '(2016)',\n",
       " '(2018)',\n",
       " '(1992)',\n",
       " '(2004)',\n",
       " '(2019)',\n",
       " '(2015)',\n",
       " '(2009)',\n",
       " '(2021)',\n",
       " '(2020)',\n",
       " '(2019)',\n",
       " '(2007)',\n",
       " '(1991)',\n",
       " '(2019)',\n",
       " '(2021)',\n",
       " '(2016)',\n",
       " '(2019)',\n",
       " '(2018)',\n",
       " '(1993)',\n",
       " '(1956)',\n",
       " '(1983)',\n",
       " '(1957)',\n",
       " '(2018)',\n",
       " '(2018)',\n",
       " '(1965)',\n",
       " '(2015)',\n",
       " '(2002)',\n",
       " '(1997)',\n",
       " '(1975)',\n",
       " '(1995)',\n",
       " '(2019)',\n",
       " '(2019)',\n",
       " '(2018)',\n",
       " '(2013)',\n",
       " '(2016)',\n",
       " '(2017)',\n",
       " '(2006)',\n",
       " '(2018)',\n",
       " '(2006)',\n",
       " '(2015)',\n",
       " '(2005)',\n",
       " '(1971)',\n",
       " '(2014)',\n",
       " '(2014)',\n",
       " '(1999)',\n",
       " '(2016)',\n",
       " '(1998)',\n",
       " '(2018)',\n",
       " '(2015)',\n",
       " '(2013)',\n",
       " '(2012)',\n",
       " '(2014)',\n",
       " '(2012)',\n",
       " '(2003)',\n",
       " '(2012)',\n",
       " '(2013)',\n",
       " '(2000)',\n",
       " '(2016)',\n",
       " '(2015)',\n",
       " '(1975)',\n",
       " '(2004)',\n",
       " '(2007)',\n",
       " '(2012)',\n",
       " '(2005)',\n",
       " '(2015)',\n",
       " '(2011)',\n",
       " '(1992)',\n",
       " '(2016)',\n",
       " '(1960)',\n",
       " '(2015)',\n",
       " '(1964)',\n",
       " '(2010)',\n",
       " '(2017)',\n",
       " '(2019)',\n",
       " '(2008)',\n",
       " '(2013)',\n",
       " '(2015)',\n",
       " '(2003)',\n",
       " '(2000)',\n",
       " '(1999)',\n",
       " '(1995)',\n",
       " '(2001)',\n",
       " '(2019)',\n",
       " '(2012)',\n",
       " '(1992)',\n",
       " '(2006)',\n",
       " '(2004)',\n",
       " '(1994)',\n",
       " '(2001)',\n",
       " '(2012)',\n",
       " '(2018)',\n",
       " '(2014)']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Release = []\n",
    "for i in release[:100]:\n",
    "    for j in i.find_all('span'):\n",
    "        Release.append(j.text.replace('\\n',''))\n",
    "Release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Names</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.      Nayakan(1987)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.      Pariyerum Perumal(2018)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.      Anbe Sivam(2003)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.      C/o Kancharapalem(2018)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.      Golmaal(1979)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.      Andaz Apna Apna(1994)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.      Lagaan: Once Upon a Time in India(2001)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.      Kahaani(2012)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.      Uri: The Surgical Strike(2018)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.      PK(2014)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2014)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Movie Names Ratings Year of Release\n",
       "0                              1.      Nayakan(1987)     8.5          (1987)\n",
       "1                    2.      Pariyerum Perumal(2018)     8.5          (2018)\n",
       "2                           3.      Anbe Sivam(2003)     8.5          (2003)\n",
       "3                    4.      C/o Kancharapalem(2018)     8.5          (2018)\n",
       "4                              5.      Golmaal(1979)     8.5          (1979)\n",
       "..                                               ...     ...             ...\n",
       "95                    96.      Andaz Apna Apna(1994)     8.1          (1994)\n",
       "96  97.      Lagaan: Once Upon a Time in India(2001)     8.1          (2001)\n",
       "97                            98.      Kahaani(2012)     8.1          (2012)\n",
       "98           99.      Uri: The Surgical Strike(2018)     8.1          (2018)\n",
       "99                                100.      PK(2014)     8.1          (2014)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['Movie Names'] = Movies\n",
    "data['Ratings'] = Ratings\n",
    "data['Year of Release'] = Release \n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q.4 Write a python program to scrap book name, author name, genre and book review of any 5 books from\n",
    "'www.bookpage.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "page4 = requests.get('https://bookpage.com/reviews/')\n",
    "soup = BeautifulSoup(page4.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = soup.find_all('h4', class_=\"italic\")\n",
    "author = soup.find_all('p',class_=\"sans bold\")\n",
    "genre = soup.find_all('p',class_=\"genre-links hidden-phone\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Book_Name = []\n",
    "Author_Name = []\n",
    "Genre = []\n",
    "Review = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  I Am the Subway',\n",
       " 'Being Clem',\n",
       " '  How to Find Your Way in the Dark',\n",
       " 'Hold Fast Through the Fire',\n",
       " 'A Good Day for Chardonnay']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in book[:5]:\n",
    "    for j in i.find_all('a'):\n",
    "        Book_Name.append(j.text.replace('\\n','').replace('★',''))\n",
    "Book_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kim Hyo-eun, Deborah Smith',\n",
       " 'Lesa Cline-Ransome',\n",
       " 'Derek B. Miller',\n",
       " 'K.B. Wagers',\n",
       " 'Darynda Jones']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in author[:5]:\n",
    "    Author_Name.append(i.text.replace('\\n',''))\n",
    "Author_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Children's / Children's Picture Book\",\n",
       " \"Children's / Middle Grade\",\n",
       " 'Fiction / Coming of Age',\n",
       " 'Science Fiction & Fantasy / Science Fiction',\n",
       " 'Mystery & Suspense / Mystery']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in genre[:5]:\n",
    "    Genre.append(i.text.replace('\\n',''))\n",
    "Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h4 class=\"italic\">\n",
       " <a href=\"/reviews/26487-kim-hyo-eun-i-am-subway-childrens\"> <span style=\"font-style:normal;\">★ </span>I Am the Subway</a>\n",
       " </h4>,\n",
       " <h4 class=\"italic\">\n",
       " <a href=\"/reviews/26484-lesa-cline-ransome-being-clem-childrens\">Being Clem</a>\n",
       " </h4>,\n",
       " <h4 class=\"italic\">\n",
       " <a href=\"/reviews/26469-derek-b-miller-how-to-find-your-way-dark-fiction\"> <span style=\"font-style:normal;\">★ </span>How to Find Your Way in the Dark</a>\n",
       " </h4>,\n",
       " <h4 class=\"italic\">\n",
       " <a href=\"/reviews/26544-k-b-wagers-hold-fast-through-fire-science-fiction-fantasy\">Hold Fast Through the Fire</a>\n",
       " </h4>,\n",
       " <h4 class=\"italic\">\n",
       " <a href=\"/reviews/26542-darynda-jones-good-day-chardonnay-mystery-suspense\">A Good Day for Chardonnay</a>\n",
       " </h4>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_tags = soup.find_all('h4', class_=\"italic\")\n",
    "url_tags[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/reviews/26487-kim-hyo-eun-i-am-subway-childrens',\n",
       " '/reviews/26484-lesa-cline-ransome-being-clem-childrens',\n",
       " '/reviews/26469-derek-b-miller-how-to-find-your-way-dark-fiction',\n",
       " '/reviews/26544-k-b-wagers-hold-fast-through-fire-science-fiction-fantasy',\n",
       " '/reviews/26542-darynda-jones-good-day-chardonnay-mystery-suspense']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = []\n",
    "\n",
    "for i in url_tags[:5]:\n",
    "    for j in i.find_all('a',href = True):\n",
    "        urls.append(j['href'])\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kim Hyo-eun’s splendid picture book, originally published in South Korea in 2016 and translated into English by Deborah Smith, is told from the perspective of a subway train in Seoul: “Carrying people from one place to another, I travel over the ground and rumble under, twice across the wide Han River.” Three full spreads introduce us to this unique voice before we even arrive at the title page. \\xa0Everyone has a story, and the train listens to and observes its passengers closely, capturing the nuances of the personalities who board at many stations. There’s Mr. Wanju, always running for the train so that he can spend as much time as possible at home with his daughter. There’s Mr. Jae-sung, a cobbler who “can tell so much about a person just from looking at their shoes.” There’s Na-yoon, a student taking classes after school who is “so tired she’s barely awake.” In alternating spreads that briefly shift among the different riders’ points of view, we follow these characters into their lives beyond the subway’s cars.Thanks to the subway train’s musings, readers gain poignant glimpses into the joys, sorrows and hopes of these passengers. The train’s voice is tender and compassionate, and the sound of its movement, “ba-dum, ba-dum, ba-dum, ba-dum,” is a refrain that anchors the book.\\xa0Early spreads feature smudgy faces in shadow, but the faces of the riders whom the subway introduces are distinct and detailed. Kim’s eloquent, fine-lined watercolor illustrations capture the commuters’ humanity and the beauty in what might otherwise be dismissed as mundane. In a striking closing spread, “a gentle afternoon light . . . washes over everything,” and the image’s composition draws our attention not to the subway riders in the upper left-hand corner of the spread but to the light hitting the floor of the car—the extraordinary amid the ordinary.\\xa0A poetic tribute to Seoul and its people, I Am the Subway makes for an unforgettable journey. Ba-dum, ba-dum, ba-dum, ba-dum.',\n",
       " \"On the very first page of Lesa Cline-Ransome’s Being Clem, a knock at the door brings terrible news: Clem’s father has been killed in the 1944 shipyard munitions accident that will become known as the Port Chicago disaster. Clem’s mother, unable to find anyone willing to hire a Black secretary, is soon behind on the rent, and his older sisters, busy with friends and boys, have little time for their little brother’s grief.\\xa0When Clem skips a grade to attend middle school, he begins hanging out with Lymon, a new boy in town. But when Lymon begins to bully another new boy, Langston, who shares Clem's affinity for the local public library, Clem must make a difficult choice. Should he go along with Lymon, despite his misgivings, or stand up for the new boy—but risk losing a friend in the process?As if all this weren’t enough for one boy to deal with, Clem's swimming lessons aren’t going smoothly either. How can Clem grow up to be a Navy man like his father when he’s afraid of the pool? Clem may know all the answers in school, but there's still so much he doesn't understand.Although Being Clem can be read independently, fans of Cline-Ransome’s previous books Finding Langston (which received a Coretta Scott King Honor) and Leaving Lymon will appreciate the daring narrative choice to place Clem in friendships with her two previous protagonists—who are, in turn, one another's enemies.\\xa0Cline-Ransome also fills Being Clem with rich details from 1940s Chicago, including the real-life, award-winning DuSable High School swim team, whose members were Black and against whom some white teams refused to compete. Cline-Ransome explores societal issues of race, class and gender alongside Clem's more internal struggles to express difficult emotions like fear and sadness. Being Clem gains poignancy from Clem’s personal journey as he mourns the father for whom he is named and whose legacy he hopes he will one day honor.\\xa0ALSO IN BOOKPAGE: Being Clem author Lesa Cline-Ransome reveals the real-life inspiration behind Clem and his friends. \",\n",
       " 'Prepare for surprises galore in How to Find Your Way in the Dark, a rollicking novel that begins with a lonely truck ride in New England in 1938 and follows its characters through a decade of fascinating history. Just when you think the story is heading one way, it veers in another, completely unexpected direction.Twelve-year-old Sheldon Horowitz and his father are driving home from Hartford, Connecticut, to Whately, Massachusetts, after honoring the one-year anniversary of Sheldon’s mother’s death. She and her sister died in a horrific movie theater fire in Hartford. And as if that isn’t enough tragedy for the novel’s first 13 pages, a truck purposely forces Sheldon and his father’s car off the road during their return trip, and Sheldon’s father dies.Readers of Derek B. Miller’s award-winning thriller, Norwegian by Night, will recognize Sheldon as that novel’s 82-year-old protagonist. As a Tom Sawyer-like boy in How to Find Your Way in the Dark, Sheldon is determined to make sense of his double tragedies, and his attempts to do so take the reader on one hell of a ride. As he seeks out the leering, mustached truck driver who killed his father, his quest leads him straight into danger—think mobsters, guns and jewel thefts.Miller has crafted a wide-ranging, years-spanning yet tightly structured plot, and he excels at placing memorable characters in unusual circumstances. Sheldon is joined in his adventures by his two older cousins, Abe and Mirabelle, and his best friend, Lenny, all of whom play pivotal roles. One summer, Lenny and Sheldon end up as bellhops at the famed Grossinger’s Resort in the Catskills, where Lenny practices standup comedy amid the glamorous, bustling atmosphere.An underlying seriousness lies at the heart of all of this intrigue, hilarity and fun. Sheldon, Abe, Mirabelle and Lenny, all Jewish, must confront the many faces of antisemitism during the turbulent years of World War II. Miller weaves in a multitude of historical details, including reports of the horrors in Europe and America’s reluctance to intervene.The ending of How to Find Your Way in the Dark is nothing short of brilliant, tying up a variety of loose ends while making a powerful statement about the need to fully recognize and address antisemitism. Readers are left with much to ponder, including life’s many uncertainties and cruel twists of fate. Despite these unhappy truths, we are also left with the uplifting wisdom of Lenny’s urgent prayer: “Dear God, give me the strength to be joyful.”',\n",
       " 'Looking for a quick bit of adrenaline, a spot of intrigue and the drama of an international sports event? Look no further than the second entry in K.B. Wagers’ NeoG series, Hold Fast Through the Fire.This second book in the author’s military science fiction series picks up roughly a year after the events of A Pale Light in the Black. The crew of Zuma’s Ghost have achieved a repeat victory at the intermilitary Boarding Games, which was quite an achievement given that the Near-Earth Orbital Guard (NeoG) are looked down upon by other branches of the armed forces. Zuma’s Ghost is facing a change of staff, and everyone is uneasy about what that means for the future of the ship. The prelims for the next year’s Games are fast approaching, and the Ghost has been put on a new task force to investigate potential smuggling issues from off-world settlements.Nika, still off balance from the loss of his hand, is apprehensive about his new command on Zuma’s Ghost, despite the fact that it was the ship where he cut his teeth as a budding lieutenant. His budding romance with Maxine Carmichael is on the rocks, and to make things worse, he has accepted a secret assignment that will put both Max’s and the crew’s trust to the test. Chae, Zuma’s Ghost’s new pilot, has issues of their own. Forced into the NeoG as part of a plea bargain, they are torn between their growing loyalty to their new crew and the need to keep their fathers safe from intergalactic intrigue. Meanwhile, Max is certain something is desperately wrong with Nika, Chae and their new assignment, but no one will back her up. With Nika effectively gaslighting her to throw her off the scent of his new top-secret mission, Max will have to hew closely to her own instincts if she is going to get the team through the prelims in one piece—let alone their official assignment.Unlike A Pale Light in the Black, Hold Fast Through the Fire’s central mystery begins unrolling nearly at page one, giving the book a more sinister feel than its predecessor and pulling readers into a labyrinthine plot that surprises and delights. This does take away slightly from the Games aspect of the series, but readers who enjoyed A Pale Light in the Black’s focus on the competition won’t be disappointed. When training for the Games does make its appearance, it still packs the same adrenaline-filled punch of A Pale Light in the Black. Despite the increase in intrigue, Wagers devotes ample attention to the relationships among the crew of Zuma’s Ghost. From the exploration of Jenks’ and Max’s close friendship to Chae’s struggles to fit in with the group to Nika’s battle to accept himself after his accident, Hold Fast Through the Fire is as much about found family and interpersonal relationships as it is about mysteries or the Boarding Games.This brilliant and entertaining installment in the NeoG universe is a great choice for readers looking for military drama, evocative writing and espionage.',\n",
       " 'Readers who enjoy murder mysteries\\xa0with lots of intertwined plotlines, quirky characters and zany hijinks topped off with a healthy dose of horniness will be delighted by bestselling author Darynda Jones’ A Good Day for Chardonnay.The small tourist town of Del Sol, New Mexico, is populated by unruly residents who are staunchly community-minded and happen to be, per Sheriff Sunshine Vicram’s hilariously lusty inner monologues, quite desirable. To wit, her chief deputy and BFF Quincy is “sexy feet, AF inches” tall. And her lifelong crush, local-badboy-turned-wealthy-distillery-owner Levi Ravinder? Well, he and his crime-aficionado family look “as though [they were] chiseled by the gods . . . [with] lean, solid bodies and razor-sharp jawlines.”But while Sunshine is often mightily distracted by eye candy, she’s also dedicated to—and excellent at—her job. She’s been back in town for four months after being away for 15 years, and she has multiple mysteries to solve. The newest include a bar fight gone terribly wrong; resurfaced cold cases with ties to her own traumatic past; and a raft of false confessions. On top of that, the mayor is pressuring her to figure out if the Dangerous Daughters secret society (rumored to have run the town for decades) is real or just local legend.And then there’s Sunshine’s daughter Auri, whom fans met in series kickoff A Bad Day for Sunshine. The smart, reckless teenager is determined to solve crimes just like her mom, and she pursues a sweet old lady who might be a serial killer. Auri is also Sunshine’s personal mystery: at 17, the sheriff was abducted by Levi’s uncle and held captive for five days, after which she emerged pregnant and with severe memory loss.Will Levi’s family finally answer Sunshine’s questions about her abduction? Can she catch the marauding raccoon that’s terrorizing the town? How are the cold cases tied to these complex new crimes? With her trademark warmth and humor, Jones answers some of these questions and raises even more, nicely teeing up the next installment in Sunshine’s complicated, sexy and highly entertaining life story.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Review = []\n",
    "\n",
    "for i in urls[:5]:\n",
    "    book = requests.get('https://bookpage.com'+i)\n",
    "    soup = BeautifulSoup(book.content,'html.parser')\n",
    "    rev = soup.find('div',class_=\"article-body\")\n",
    "    Review.append(rev.text.replace('\\n',''))\n",
    "Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I Am the Subway</td>\n",
       "      <td>Kim Hyo-eun, Deborah Smith</td>\n",
       "      <td>Children's / Children's Picture Book</td>\n",
       "      <td>Kim Hyo-eun’s splendid picture book, originall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Being Clem</td>\n",
       "      <td>Lesa Cline-Ransome</td>\n",
       "      <td>Children's / Middle Grade</td>\n",
       "      <td>On the very first page of Lesa Cline-Ransome’s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to Find Your Way in the Dark</td>\n",
       "      <td>Derek B. Miller</td>\n",
       "      <td>Fiction / Coming of Age</td>\n",
       "      <td>Prepare for surprises galore in How to Find Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hold Fast Through the Fire</td>\n",
       "      <td>K.B. Wagers</td>\n",
       "      <td>Science Fiction &amp; Fantasy / Science Fiction</td>\n",
       "      <td>Looking for a quick bit of adrenaline, a spot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Good Day for Chardonnay</td>\n",
       "      <td>Darynda Jones</td>\n",
       "      <td>Mystery &amp; Suspense / Mystery</td>\n",
       "      <td>Readers who enjoy murder mysteries with lots o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Book Name                      Author  \\\n",
       "0                     I Am the Subway  Kim Hyo-eun, Deborah Smith   \n",
       "1                          Being Clem          Lesa Cline-Ransome   \n",
       "2    How to Find Your Way in the Dark             Derek B. Miller   \n",
       "3          Hold Fast Through the Fire                 K.B. Wagers   \n",
       "4           A Good Day for Chardonnay               Darynda Jones   \n",
       "\n",
       "                                         Genre  \\\n",
       "0         Children's / Children's Picture Book   \n",
       "1                    Children's / Middle Grade   \n",
       "2                      Fiction / Coming of Age   \n",
       "3  Science Fiction & Fantasy / Science Fiction   \n",
       "4                 Mystery & Suspense / Mystery   \n",
       "\n",
       "                                              Review  \n",
       "0  Kim Hyo-eun’s splendid picture book, originall...  \n",
       "1  On the very first page of Lesa Cline-Ransome’s...  \n",
       "2  Prepare for surprises galore in How to Find Yo...  \n",
       "3  Looking for a quick bit of adrenaline, a spot ...  \n",
       "4  Readers who enjoy murder mysteries with lots o...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd = pd.DataFrame()\n",
    "bd['Book Name'] = Book_Name \n",
    "bd['Author'] = Author_Name \n",
    "bd['Genre'] = Genre \n",
    "bd['Review'] =  Review\n",
    "\n",
    "bd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.5 Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "#### i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "page5 = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "\n",
    "soup = BeautifulSoup(page5.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "points = []\n",
    "rating = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "match_1= soup.find_all('td',class_=\"rankings-block__banner--matches\")\n",
    "Rmatch = soup.find_all('td',class_=\"table-body__cell u-center-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in match_1:\n",
    "    matches.append(i.text)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17',\n",
       " '32',\n",
       " '27',\n",
       " '32',\n",
       " '22',\n",
       " '27',\n",
       " '29',\n",
       " '29',\n",
       " '29',\n",
       " '17',\n",
       " '7',\n",
       " '23',\n",
       " '17',\n",
       " '7',\n",
       " '7',\n",
       " '5',\n",
       " '9',\n",
       " '6',\n",
       " '8',\n",
       " '5']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_matches = []\n",
    "for i in Rmatch:\n",
    "    re_matches.append(i.text)\n",
    "re_matches\n",
    "\n",
    "for i in range(0,len(re_matches),2):\n",
    "    matches.append(re_matches[i])\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "points =  []\n",
    "p_match1 = soup.find_all('td',class_=\"rankings-block__banner--points\")\n",
    "p_remain = soup.find_all('td',class_=\"table-body__cell u-center-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,054']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in p_match1:\n",
    "    points.append(i.text)\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,054',\n",
       " '3,793',\n",
       " '3,109',\n",
       " '3,624',\n",
       " '2,267',\n",
       " '2,524',\n",
       " '2,639',\n",
       " '2,458',\n",
       " '2,303',\n",
       " '1,054',\n",
       " '336',\n",
       " '1,067',\n",
       " '646',\n",
       " '258',\n",
       " '240',\n",
       " '119',\n",
       " '190',\n",
       " '97',\n",
       " '93',\n",
       " '0']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remain_points = []\n",
    "for i in p_remain:\n",
    "    remain_points.append(i.text)\n",
    "remain_points\n",
    "    \n",
    "for i in range(1,len(remain_points),2):\n",
    "    points.append(remain_points[i])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = []\n",
    "\n",
    "r_match1 = soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "remain_rating = soup.find_all('td',class_=\"table-body__cell u-text-right rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['121']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in r_match1:\n",
    "    rating.append(i.text.strip())\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['121',\n",
       " '119',\n",
       " '115',\n",
       " '113',\n",
       " '103',\n",
       " '93',\n",
       " '91',\n",
       " '85',\n",
       " '79',\n",
       " '62',\n",
       " '48',\n",
       " '46',\n",
       " '38',\n",
       " '37',\n",
       " '34',\n",
       " '24',\n",
       " '21',\n",
       " '16',\n",
       " '12',\n",
       " '0']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in remain_rating:\n",
    "    rating.append(i.text)\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New Zealand',\n",
       " 'England',\n",
       " 'Australia',\n",
       " 'India',\n",
       " 'South Africa',\n",
       " 'Pakistan',\n",
       " 'Bangladesh',\n",
       " 'West Indies',\n",
       " 'Sri Lanka',\n",
       " 'Afghanistan',\n",
       " 'Netherlands',\n",
       " 'Ireland',\n",
       " 'Zimbabwe',\n",
       " 'Scotland',\n",
       " 'Oman',\n",
       " 'Nepal',\n",
       " 'UAE',\n",
       " 'Namibia',\n",
       " 'United States',\n",
       " 'Papua New Guinea']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_teams = []\n",
    "teams = soup.find_all('span',class_=\"u-hide-phablet\")\n",
    "\n",
    "for i in teams[:20]:\n",
    "    top_teams.append(i.text)\n",
    "top_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Top Teams\"] = top_teams\n",
    "df['Matches'] = matches\n",
    "df['Points']  = points\n",
    "df['Rating']= rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>32</td>\n",
       "      <td>3,793</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>27</td>\n",
       "      <td>3,109</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>32</td>\n",
       "      <td>3,624</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>22</td>\n",
       "      <td>2,267</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>2,524</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>29</td>\n",
       "      <td>2,639</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>29</td>\n",
       "      <td>2,458</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>29</td>\n",
       "      <td>2,303</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>17</td>\n",
       "      <td>1,054</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Top Teams Matches Points Rating\n",
       "0   New Zealand      17  2,054    121\n",
       "1       England      32  3,793    119\n",
       "2     Australia      27  3,109    115\n",
       "3         India      32  3,624    113\n",
       "4  South Africa      22  2,267    103\n",
       "5      Pakistan      27  2,524     93\n",
       "6    Bangladesh      29  2,639     91\n",
       "7   West Indies      29  2,458     85\n",
       "8     Sri Lanka      29  2,303     79\n",
       "9   Afghanistan      17  1,054     62"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii Top 10 ODI Batsmen in men along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpage_1 = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "soup = BeautifulSoup(subpage_1.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players = []\n",
    "Teams = []\n",
    "Ranking = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_1 = soup.find_all('div',class_=\"rankings-block__banner--name-large\")\n",
    "rplayers = soup.find_all('td',class_=\"table-body__cell rankings-table__name name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Babar Azam']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in player_1:\n",
    "    Players.append(i.text)\n",
    "Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Babar Azam',\n",
       " 'Virat Kohli',\n",
       " 'Rohit Sharma',\n",
       " 'Ross Taylor',\n",
       " 'Aaron Finch',\n",
       " 'Jonny Bairstow',\n",
       " 'David Warner',\n",
       " 'Quinton de Kock',\n",
       " 'Shai Hope',\n",
       " 'Kane Williamson',\n",
       " 'Fakhar Zaman',\n",
       " 'Joe Root',\n",
       " 'Mushfiqur Rahim',\n",
       " 'Imam-ul-Haq',\n",
       " 'Martin Guptill',\n",
       " 'Shikhar Dhawan',\n",
       " 'Steve Smith',\n",
       " 'Jason Roy',\n",
       " 'Rassie van der Dussen',\n",
       " 'Glenn Maxwell',\n",
       " 'Tamim Iqbal',\n",
       " 'Alex Carey',\n",
       " 'Paul Stirling',\n",
       " 'Ben Stokes',\n",
       " 'Eoin Morgan',\n",
       " 'Shakib Al Hasan',\n",
       " 'Lokesh Rahul',\n",
       " 'David Miller',\n",
       " 'Tom Latham',\n",
       " 'Nicholas Pooran',\n",
       " 'Jos Buttler',\n",
       " 'Shimron Hetmyer',\n",
       " 'Haris Sohail',\n",
       " 'Henry Nicholls',\n",
       " 'Aqib Ilyas',\n",
       " 'Andrew Balbirnie',\n",
       " 'Kyle Coetzer',\n",
       " 'Brendan Taylor',\n",
       " 'Mahmudullah',\n",
       " 'Kusal Perera',\n",
       " 'Rahmat Shah',\n",
       " 'Evin Lewis',\n",
       " 'Litton Das',\n",
       " 'Sean Williams',\n",
       " 'Kedar Jadhav',\n",
       " 'Angelo Mathews',\n",
       " 'Hardik Pandya',\n",
       " 'Sikandar Raza',\n",
       " 'Danushka Gunathilaka',\n",
       " 'Kusal Mendis',\n",
       " 'Imad Wasim',\n",
       " 'Avishka Fernando',\n",
       " 'Soumya Sarkar',\n",
       " 'Marcus Stoinis',\n",
       " 'Calum MacLeod',\n",
       " 'Colin de Grandhomme',\n",
       " 'Najibullah Zadran',\n",
       " 'Sarfaraz Ahmed',\n",
       " 'Niroshan Dickwella',\n",
       " 'Hashmatullah Shaidi',\n",
       " 'Marnus Labuschagne',\n",
       " 'Jimmy Neesham',\n",
       " 'Mohammad Nabi',\n",
       " 'Mitchell Marsh',\n",
       " 'Janneman Malan',\n",
       " 'Asghar Afghan',\n",
       " 'Richard Berrington',\n",
       " 'Shreyas Iyer',\n",
       " 'Muhammad Usman',\n",
       " 'William Porterfield',\n",
       " 'Dhananjaya de Silva',\n",
       " 'Mitchell Santner',\n",
       " 'Craig Ervine',\n",
       " 'Jason Holder',\n",
       " 'Aiden Markram',\n",
       " 'Temba Bavuma',\n",
       " 'Heinrich Klaasen',\n",
       " 'Andile Phehlukwayo',\n",
       " 'Assad Vala',\n",
       " 'Lahiru Thirimanne',\n",
       " 'Harry Tector',\n",
       " 'Ravindra Jadeja',\n",
       " 'Mithun Ali',\n",
       " 'Rashid Khan',\n",
       " 'George Munsey',\n",
       " 'Rishabh Pant',\n",
       " 'Matthew Wade',\n",
       " 'Rovman Powell',\n",
       " 'Curtis Campher',\n",
       " 'Dasun Shanaka',\n",
       " 'Dinesh Chandimal',\n",
       " 'Kieron Pollard',\n",
       " 'Gulbadin Naib',\n",
       " 'Mohammad Rizwan',\n",
       " 'Tony Ura',\n",
       " 'Moeen Ali',\n",
       " 'Wanindu De Silva',\n",
       " 'Chris Woakes',\n",
       " 'Simi Singh',\n",
       " 'Matthew Cross']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in rplayers:\n",
    "    Players.append(i.text.replace('\\n',''))\n",
    "Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Teams = []\n",
    "\n",
    "team_1 = soup.find_all('div',class_=\"rankings-block__banner--nationality\")\n",
    "rteam = soup.find_all('span',class_=\"table-body__logo-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAK']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in team_1:\n",
    "    Teams.append(i.text.replace('\\n','').strip())\n",
    "Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAK',\n",
       " 'IND',\n",
       " 'IND',\n",
       " 'NZ',\n",
       " 'AUS',\n",
       " 'ENG',\n",
       " 'AUS',\n",
       " 'SA',\n",
       " 'WI',\n",
       " 'NZ',\n",
       " 'PAK',\n",
       " 'ENG',\n",
       " 'BAN',\n",
       " 'PAK',\n",
       " 'NZ',\n",
       " 'IND',\n",
       " 'AUS',\n",
       " 'ENG',\n",
       " 'SA',\n",
       " 'AUS',\n",
       " 'BAN',\n",
       " 'AUS',\n",
       " 'IRE',\n",
       " 'ENG',\n",
       " 'ENG',\n",
       " 'BAN',\n",
       " 'IND',\n",
       " 'SA',\n",
       " 'NZ',\n",
       " 'WI',\n",
       " 'ENG',\n",
       " 'WI',\n",
       " 'PAK',\n",
       " 'NZ',\n",
       " 'OMA',\n",
       " 'IRE',\n",
       " 'SCO',\n",
       " 'ZIM',\n",
       " 'BAN',\n",
       " 'SL',\n",
       " 'AFG',\n",
       " 'WI',\n",
       " 'BAN',\n",
       " 'ZIM',\n",
       " 'IND',\n",
       " 'SL',\n",
       " 'IND',\n",
       " 'ZIM',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'PAK',\n",
       " 'SL',\n",
       " 'BAN',\n",
       " 'AUS',\n",
       " 'SCO',\n",
       " 'NZ',\n",
       " 'AFG',\n",
       " 'PAK',\n",
       " 'SL',\n",
       " 'AFG',\n",
       " 'AUS',\n",
       " 'NZ',\n",
       " 'AFG',\n",
       " 'AUS',\n",
       " 'SA',\n",
       " 'AFG',\n",
       " 'SCO',\n",
       " 'IND',\n",
       " 'UAE',\n",
       " 'IRE',\n",
       " 'SL',\n",
       " 'NZ',\n",
       " 'ZIM',\n",
       " 'WI',\n",
       " 'SA',\n",
       " 'SA',\n",
       " 'SA',\n",
       " 'SA',\n",
       " 'PNG',\n",
       " 'SL',\n",
       " 'IRE',\n",
       " 'IND',\n",
       " 'BAN',\n",
       " 'AFG',\n",
       " 'SCO',\n",
       " 'IND',\n",
       " 'AUS',\n",
       " 'WI',\n",
       " 'IRE',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'WI',\n",
       " 'AFG',\n",
       " 'PAK',\n",
       " 'PNG',\n",
       " 'ENG',\n",
       " 'SL',\n",
       " 'ENG',\n",
       " 'IRE',\n",
       " 'SCO']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in rteam:\n",
    "    Teams.append(i.text)\n",
    "Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_1 = soup.find_all('div',class_=\"rankings-block__banner--rating\")\n",
    "r_rank = soup.find_all('td',class_=\"table-body__cell rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['873']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ranking = []\n",
    "for i in rank_1:\n",
    "    Ranking.append(i.text)\n",
    "Ranking\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['873',\n",
       " '844',\n",
       " '813',\n",
       " '801',\n",
       " '779',\n",
       " '775',\n",
       " '762',\n",
       " '758',\n",
       " '758',\n",
       " '754',\n",
       " '741',\n",
       " '740',\n",
       " '723',\n",
       " '717',\n",
       " '707',\n",
       " '704',\n",
       " '696',\n",
       " '687',\n",
       " '678',\n",
       " '674',\n",
       " '670',\n",
       " '669',\n",
       " '664',\n",
       " '651',\n",
       " '650',\n",
       " '641',\n",
       " '636',\n",
       " '632',\n",
       " '624',\n",
       " '615',\n",
       " '608',\n",
       " '607',\n",
       " '594',\n",
       " '581',\n",
       " '578',\n",
       " '575',\n",
       " '573',\n",
       " '572',\n",
       " '571',\n",
       " '560',\n",
       " '559',\n",
       " '558',\n",
       " '558',\n",
       " '553',\n",
       " '552',\n",
       " '550',\n",
       " '548',\n",
       " '540',\n",
       " '538',\n",
       " '526',\n",
       " '525',\n",
       " '522',\n",
       " '521',\n",
       " '517',\n",
       " '508',\n",
       " '507',\n",
       " '506',\n",
       " '504',\n",
       " '503',\n",
       " '498',\n",
       " '498',\n",
       " '495',\n",
       " '494',\n",
       " '489',\n",
       " '485',\n",
       " '479',\n",
       " '479',\n",
       " '472',\n",
       " '471',\n",
       " '471',\n",
       " '461',\n",
       " '460',\n",
       " '457',\n",
       " '446',\n",
       " '445',\n",
       " '443',\n",
       " '442',\n",
       " '439',\n",
       " '439',\n",
       " '436',\n",
       " '434',\n",
       " '434',\n",
       " '433',\n",
       " '432',\n",
       " '430',\n",
       " '426',\n",
       " '424',\n",
       " '419',\n",
       " '418',\n",
       " '418',\n",
       " '417',\n",
       " '416',\n",
       " '415',\n",
       " '414',\n",
       " '412',\n",
       " '404',\n",
       " '403',\n",
       " '403',\n",
       " '402',\n",
       " '398']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in r_rank:\n",
    "    Ranking.append(i.text)\n",
    "Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>NZ</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Player Team Ranking\n",
       "0       Babar Azam  PAK     873\n",
       "1      Virat Kohli  IND     844\n",
       "2     Rohit Sharma  IND     813\n",
       "3      Ross Taylor   NZ     801\n",
       "4      Aaron Finch  AUS     779\n",
       "5   Jonny Bairstow  ENG     775\n",
       "6     David Warner  AUS     762\n",
       "7  Quinton de Kock   SA     758\n",
       "8        Shai Hope   WI     758\n",
       "9  Kane Williamson   NZ     754"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['Player'] = Players \n",
    "df['Team'] = Teams\n",
    "df['Ranking'] = Ranking\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpage_2 = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "soup = BeautifulSoup(subpage_2.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Player = []\n",
    "\n",
    "player1 = soup.find_all('div',class_=\"rankings-block__banner--name-large\")\n",
    "r_player = soup.find_all('td',class_=\"table-body__cell rankings-table__name name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trent Boult']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in player1:\n",
    "    Player.append(i.text)\n",
    "Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trent Boult',\n",
       " 'Josh Hazlewood',\n",
       " 'Mujeeb Ur Rahman',\n",
       " 'Chris Woakes',\n",
       " 'Mehedi Hasan',\n",
       " 'Matt Henry',\n",
       " 'Jasprit Bumrah',\n",
       " 'Mitchell Starc',\n",
       " 'Shakib Al Hasan',\n",
       " 'Kagiso Rabada',\n",
       " 'Mustafizur Rahman',\n",
       " 'Pat Cummins',\n",
       " 'Shaheen Afridi',\n",
       " 'Mohammad Amir',\n",
       " 'Rashid Khan',\n",
       " 'Adam Zampa',\n",
       " 'Bhuvneshwar Kumar',\n",
       " 'Lachlan Ferguson',\n",
       " 'Jofra Archer',\n",
       " 'Akila Dananjaya',\n",
       " 'Yuzvendra Chahal',\n",
       " 'Lungi Ngidi',\n",
       " 'Mohammad Nabi',\n",
       " 'Mark Wood',\n",
       " 'Alzarri Joseph',\n",
       " 'Mitchell Santner',\n",
       " 'Mohammad Shami',\n",
       " 'Kuldeep Yadav',\n",
       " 'Ravindra Jadeja',\n",
       " 'Sheldon Cottrell',\n",
       " 'Ahmed Raza',\n",
       " 'Andy McBrine',\n",
       " 'Shadab Khan',\n",
       " 'Dushmantha Chameera',\n",
       " 'Wanindu De Silva',\n",
       " 'Colin de Grandhomme',\n",
       " 'Tabraiz Shamsi',\n",
       " 'David Willey',\n",
       " 'Tim Southee',\n",
       " 'Andile Phehlukwayo',\n",
       " 'Adil Rashid',\n",
       " 'Ish Sodhi',\n",
       " 'Mark Watt',\n",
       " 'Imad Wasim',\n",
       " 'Hasan Ali',\n",
       " 'Usman Khan',\n",
       " 'Jhye Richardson',\n",
       " 'Rohan Mustafa',\n",
       " 'Simi Singh',\n",
       " 'Mashrafe Mortaza',\n",
       " 'Mohammad Mohammad Saifuddin',\n",
       " 'Safyaan Sharif',\n",
       " 'Tendai Chatara',\n",
       " 'Nuwan Pradeep',\n",
       " 'Jimmy Neesham',\n",
       " 'Saqib Mahmood',\n",
       " 'Jason Holder',\n",
       " 'Moeen Ali',\n",
       " 'Wahab Riaz',\n",
       " 'Faheem Ashraf',\n",
       " 'Akeal Hosein',\n",
       " 'Suranga Lakmal',\n",
       " 'Sikandar Raza',\n",
       " 'Blessing Muzarabani',\n",
       " 'Tom Curran',\n",
       " 'Ashton Agar',\n",
       " 'Taskin Ahmed',\n",
       " 'Anrich Nortje',\n",
       " 'Josh Davey',\n",
       " 'Joshua Little',\n",
       " 'Craig Young',\n",
       " 'Sean Williams',\n",
       " 'Kane Richardson',\n",
       " 'Ben Stokes',\n",
       " 'Shardul Thakur',\n",
       " 'Rubel Hossain',\n",
       " 'Gulbadin Naib',\n",
       " 'Hardik Pandya',\n",
       " 'Alasdair Evans',\n",
       " 'Keshav Maharaj',\n",
       " 'Barry McCarthy',\n",
       " 'Mitchell Marsh',\n",
       " 'Dhananjaya de Silva',\n",
       " 'Marcus Stoinis',\n",
       " 'Lakshan Sandakan',\n",
       " 'Taijul Islam',\n",
       " 'Mohammad Nawaz',\n",
       " 'Donald Tiripano',\n",
       " 'Assad Vala',\n",
       " 'Fred Klaassen',\n",
       " 'George Dockrell',\n",
       " 'Oshane Thomas',\n",
       " 'Kyle Jamieson',\n",
       " 'Michael Leask',\n",
       " 'Zeeshan Maqsood',\n",
       " 'Sharafuddin Ashraf',\n",
       " 'Roston Chase',\n",
       " 'Bilal Khan',\n",
       " 'Saurabh Netravalkar',\n",
       " 'Norman Vanua']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in r_player:\n",
    "    Player.append(i.text.replace('\\n',''))\n",
    "Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "team1 = soup.find_all('div',class_=\"rankings-block__banner--nationality\")\n",
    "r_team = soup.find_all('span',class_=\"table-body__logo-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NZ',\n",
       " 'AUS',\n",
       " 'AFG',\n",
       " 'ENG',\n",
       " 'BAN',\n",
       " 'NZ',\n",
       " 'IND',\n",
       " 'AUS',\n",
       " 'BAN',\n",
       " 'SA',\n",
       " 'BAN',\n",
       " 'AUS',\n",
       " 'PAK',\n",
       " 'PAK',\n",
       " 'AFG',\n",
       " 'AUS',\n",
       " 'IND',\n",
       " 'NZ',\n",
       " 'ENG',\n",
       " 'SL',\n",
       " 'IND',\n",
       " 'SA',\n",
       " 'AFG',\n",
       " 'ENG',\n",
       " 'WI',\n",
       " 'NZ',\n",
       " 'IND',\n",
       " 'IND',\n",
       " 'IND',\n",
       " 'WI',\n",
       " 'UAE',\n",
       " 'IRE',\n",
       " 'PAK',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'NZ',\n",
       " 'SA',\n",
       " 'ENG',\n",
       " 'NZ',\n",
       " 'SA',\n",
       " 'ENG',\n",
       " '',\n",
       " 'SCO',\n",
       " 'PAK',\n",
       " 'PAK',\n",
       " 'PAK',\n",
       " 'AUS',\n",
       " 'UAE',\n",
       " 'IRE',\n",
       " 'BAN',\n",
       " 'BAN',\n",
       " 'SCO',\n",
       " 'ZIM',\n",
       " 'SL',\n",
       " 'NZ',\n",
       " 'ENG',\n",
       " 'WI',\n",
       " 'ENG',\n",
       " 'PAK',\n",
       " 'PAK',\n",
       " 'WI',\n",
       " 'SL',\n",
       " 'ZIM',\n",
       " 'ZIM',\n",
       " 'ENG',\n",
       " 'AUS',\n",
       " 'BAN',\n",
       " 'SA',\n",
       " 'SCO',\n",
       " 'IRE',\n",
       " 'IRE',\n",
       " 'ZIM',\n",
       " 'AUS',\n",
       " 'ENG',\n",
       " 'IND',\n",
       " 'BAN',\n",
       " 'AFG',\n",
       " 'IND',\n",
       " 'SCO',\n",
       " 'SA',\n",
       " 'IRE',\n",
       " 'AUS',\n",
       " 'SL',\n",
       " 'AUS',\n",
       " 'SL',\n",
       " 'BAN',\n",
       " 'PAK',\n",
       " 'ZIM',\n",
       " 'PNG',\n",
       " 'NED',\n",
       " 'IRE',\n",
       " 'WI',\n",
       " 'NZ',\n",
       " 'SCO',\n",
       " 'OMA',\n",
       " 'AFG',\n",
       " '',\n",
       " 'OMA',\n",
       " 'USA',\n",
       " 'PNG']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Team = []\n",
    "\n",
    "for i in team1:\n",
    "    Team.append(i.text.replace('\\n','').strip())\n",
    "for i in r_team:\n",
    "    Team.append(i.text)\n",
    "    \n",
    "Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank1 = soup.find_all('div',class_=\"rankings-block__banner--rating\")\n",
    "r_rank = soup.find_all('td',class_=\"table-body__cell rating\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['737',\n",
       " '709',\n",
       " '708',\n",
       " '700',\n",
       " '692',\n",
       " '691',\n",
       " '679',\n",
       " '652',\n",
       " '650',\n",
       " '648',\n",
       " '640',\n",
       " '636',\n",
       " '630',\n",
       " '628',\n",
       " '626',\n",
       " '625',\n",
       " '621',\n",
       " '619',\n",
       " '609',\n",
       " '604',\n",
       " '603',\n",
       " '599',\n",
       " '596',\n",
       " '594',\n",
       " '592',\n",
       " '583',\n",
       " '566',\n",
       " '562',\n",
       " '550',\n",
       " '541',\n",
       " '531',\n",
       " '527',\n",
       " '517',\n",
       " '514',\n",
       " '508',\n",
       " '508',\n",
       " '501',\n",
       " '501',\n",
       " '500',\n",
       " '497',\n",
       " '497',\n",
       " '496',\n",
       " '490',\n",
       " '488',\n",
       " '483',\n",
       " '482',\n",
       " '480',\n",
       " '477',\n",
       " '473',\n",
       " '469',\n",
       " '468',\n",
       " '467',\n",
       " '465',\n",
       " '459',\n",
       " '458',\n",
       " '454',\n",
       " '451',\n",
       " '449',\n",
       " '447',\n",
       " '445',\n",
       " '443',\n",
       " '443',\n",
       " '440',\n",
       " '437',\n",
       " '436',\n",
       " '436',\n",
       " '434',\n",
       " '431',\n",
       " '427',\n",
       " '421',\n",
       " '421',\n",
       " '420',\n",
       " '416',\n",
       " '410',\n",
       " '405',\n",
       " '400',\n",
       " '399',\n",
       " '394',\n",
       " '394',\n",
       " '394',\n",
       " '391',\n",
       " '390',\n",
       " '388',\n",
       " '377',\n",
       " '376',\n",
       " '374',\n",
       " '370',\n",
       " '367',\n",
       " '361',\n",
       " '358',\n",
       " '357',\n",
       " '355',\n",
       " '352',\n",
       " '351',\n",
       " '350',\n",
       " '347',\n",
       " '347',\n",
       " '344',\n",
       " '343',\n",
       " '342']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ranking = []\n",
    "\n",
    "for i in rank1:\n",
    "    Ranking.append(i.text)\n",
    "\n",
    "for i in r_rank:\n",
    "    Ranking.append(i.text)\n",
    "\n",
    "Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player Team Ranking\n",
       "0       Trent Boult   NZ     737\n",
       "1    Josh Hazlewood  AUS     709\n",
       "2  Mujeeb Ur Rahman  AFG     708\n",
       "3      Chris Woakes  ENG     700\n",
       "4      Mehedi Hasan  BAN     692\n",
       "5        Matt Henry   NZ     691\n",
       "6    Jasprit Bumrah  IND     679\n",
       "7    Mitchell Starc  AUS     652\n",
       "8   Shakib Al Hasan  BAN     650\n",
       "9     Kagiso Rabada   SA     648"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Player'] = Player\n",
    "df['Team'] = Team\n",
    "df['Ranking'] = Ranking\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.6  Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "#### i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "page6 = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "soup = BeautifulSoup(page6.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = soup.find_all('span',class_=\"u-hide-phablet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Australia',\n",
       " 'England',\n",
       " 'South Africa',\n",
       " 'India',\n",
       " 'New Zealand',\n",
       " 'West Indies',\n",
       " 'Pakistan',\n",
       " 'Bangladesh',\n",
       " 'Sri Lanka',\n",
       " 'Ireland']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Team = []\n",
    "\n",
    "for i in t1[:10]:\n",
    "    Team.append(i.text)\n",
    "Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = soup.find_all('td',class_=\"rankings-block__banner--matches\")\n",
    "m2 = soup.find_all('td',class_=\"table-body__cell u-center-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matches = []\n",
    "\n",
    "for i in m1:\n",
    "    Matches.append(i.text)\n",
    "Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18', '20', '24', '23', '21', '17', '20', '5', '11', '2']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_match = []\n",
    "\n",
    "for i in m2:\n",
    "    r_match.append(i.text)\n",
    "r_match\n",
    "\n",
    "for i in range(0,len(r_match),2):\n",
    "    Matches.append(r_match[i])\n",
    "Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = soup.find_all('td',class_=\"rankings-block__banner--points\")\n",
    "p2 = soup.find_all('td',class_=\"table-body__cell u-center-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,955']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Points = []\n",
    "\n",
    "for i in p1:\n",
    "    Points.append(i.text)\n",
    "\n",
    "Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,955',\n",
       " '2,370',\n",
       " '2,828',\n",
       " '2,535',\n",
       " '1,947',\n",
       " '1,427',\n",
       " '1,496',\n",
       " '306',\n",
       " '519',\n",
       " '25']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_points = []\n",
    "\n",
    "for i in p2:\n",
    "    r_points.append(i.text)\n",
    "r_points\n",
    "\n",
    "for i in range(1,len(r_points),2):\n",
    "    Points.append(r_points[i])\n",
    "Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "r2 = soup.find_all('td',class_=\"table-body__cell u-text-right rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['164', '119', '118', '110', '93', '84', '75', '61', '47', '13']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rating = []\n",
    "\n",
    "for i in r1:\n",
    "    Rating.append(i.text.replace('\\n','').strip())\n",
    "for i in r2:\n",
    "    Rating.append(i.text)\n",
    "Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>18</td>\n",
       "      <td>2,955</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>20</td>\n",
       "      <td>2,370</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>2,828</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>23</td>\n",
       "      <td>2,535</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>21</td>\n",
       "      <td>1,947</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>17</td>\n",
       "      <td>1,427</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>20</td>\n",
       "      <td>1,496</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Team Matches Points Rating\n",
       "0     Australia      18  2,955    164\n",
       "1       England      20  2,370    119\n",
       "2  South Africa      24  2,828    118\n",
       "3         India      23  2,535    110\n",
       "4   New Zealand      21  1,947     93\n",
       "5   West Indies      17  1,427     84\n",
       "6      Pakistan      20  1,496     75\n",
       "7    Bangladesh       5    306     61\n",
       "8     Sri Lanka      11    519     47\n",
       "9       Ireland       2     25     13"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['Team'] = Team\n",
    "df['Matches'] = Matches\n",
    "df['Points'] = Points\n",
    "df['Rating'] = Rating\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii) Top 10 women’s ODI players along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpage = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "soup = BeautifulSoup(subpage.content,'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = soup.find_all('div',class_=\"rankings-block__banner--name-large\")\n",
    "p2 = soup.find_all('td',class_=\"table-body__cell rankings-table__name name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mithali Raj',\n",
       " 'Lizelle Lee',\n",
       " 'Alyssa Healy',\n",
       " 'Tammy Beaumont',\n",
       " 'Stafanie Taylor',\n",
       " 'Meg Lanning',\n",
       " 'Amy Satterthwaite',\n",
       " 'Natalie Sciver',\n",
       " 'Smriti Mandhana',\n",
       " 'Laura Wolvaardt']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Player = []\n",
    "\n",
    "for i in p1:\n",
    "    Player.append(i.text)\n",
    "    \n",
    "for i in p2[:9]:\n",
    "    Player.append(i.text.replace('\\n',''))\n",
    "Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = soup.find_all('div',class_=\"rankings-block__banner--nationality\")\n",
    "t2 = soup.find_all('span',class_=\"table-body__logo-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IND', 'SA', 'AUS', 'ENG', 'WI', 'AUS', 'NZ', 'ENG', 'IND', 'SA']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Team = []\n",
    "\n",
    "for i in t1:\n",
    "    Team.append(i.text.replace('\\n',''))\n",
    "    \n",
    "for i in t2[:9]:\n",
    "    Team.append(i.text)\n",
    "Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = soup.find_all('div',class_=\"rankings-block__banner--rating\")\n",
    "r2 = soup.find_all('td',class_=\"table-body__cell rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['762', '758', '756', '754', '736', '723', '715', '706', '701', '683']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = []\n",
    "\n",
    "for i in r1:\n",
    "    rating.append(i.text)\n",
    "    \n",
    "for i in r2[:9]:\n",
    "    rating.append(i.text)\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>team</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              player team rating\n",
       "0        Mithali Raj  IND    762\n",
       "1        Lizelle Lee   SA    758\n",
       "2       Alyssa Healy  AUS    756\n",
       "3     Tammy Beaumont  ENG    754\n",
       "4    Stafanie Taylor   WI    736\n",
       "5        Meg Lanning  AUS    723\n",
       "6  Amy Satterthwaite   NZ    715\n",
       "7     Natalie Sciver  ENG    706\n",
       "8    Smriti Mandhana  IND    701\n",
       "9    Laura Wolvaardt   SA    683"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['player'] = Player\n",
    "df['team'] = Team\n",
    "df['rating'] = rating\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpage1 = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "soup = BeautifulSoup(subpage1.content,'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = soup.find_all('div',class_=\"rankings-block__banner--name-large\")\n",
    "p2 = soup.find_all('td',class_=\"table-body__cell rankings-table__name name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marizanne Kapp',\n",
       " 'Ellyse Perry',\n",
       " 'Stafanie Taylor',\n",
       " 'Natalie Sciver',\n",
       " 'Deepti Sharma',\n",
       " 'Jess Jonassen',\n",
       " 'Ashleigh Gardner',\n",
       " 'Dane van Niekerk',\n",
       " 'Sophie Devine',\n",
       " 'Katherine Brunt']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Player = []\n",
    "\n",
    "for i in p1:\n",
    "    Player.append(i.text)\n",
    "    \n",
    "for i in p2[:9]:\n",
    "    Player.append(i.text.replace('\\n',''))\n",
    "Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = soup.find_all('div',class_=\"rankings-block__banner--nationality\")\n",
    "t2 = soup.find_all('span',class_=\"table-body__logo-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SA', 'AUS', 'WI', 'ENG', 'IND', 'AUS', 'AUS', 'SA', 'NZ', 'ENG']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Team = []\n",
    "\n",
    "for i in t1:\n",
    "    Team.append(i.text.replace('\\n',''))\n",
    "    \n",
    "for i in t2[:9]:\n",
    "    Team.append(i.text)\n",
    "Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = soup.find_all('div',class_=\"rankings-block__banner--rating\")\n",
    "r2 = soup.find_all('td',class_=\"table-body__cell rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['418', '418', '394', '365', '331', '307', '252', '243', '242', '239']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = []\n",
    "\n",
    "for i in r1:\n",
    "    rating.append(i.text)\n",
    "    \n",
    "for i in r2[:9]:\n",
    "    rating.append(i.text)\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>team</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             player team rating\n",
       "0    Marizanne Kapp   SA    418\n",
       "1      Ellyse Perry  AUS    418\n",
       "2   Stafanie Taylor   WI    394\n",
       "3    Natalie Sciver  ENG    365\n",
       "4     Deepti Sharma  IND    331\n",
       "5     Jess Jonassen  AUS    307\n",
       "6  Ashleigh Gardner  AUS    252\n",
       "7  Dane van Niekerk   SA    243\n",
       "8     Sophie Devine   NZ    242\n",
       "9   Katherine Brunt  ENG    239"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['player'] = Player\n",
    "df['team'] = Team\n",
    "df['rating'] = rating\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Q.7 Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "page7 = requests.get('https://www.amazon.in/s?k=mobile+phones+under+20000&ref=nb_sb_noss_2')\n",
    "soup = BeautifulSoup(page7.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Redmi 9A (Nature Green, 2GB RAM, 32GB Storage) | 2GHz Octa-core Helio G25 Processor | 5000 mAh Battery',\n",
       " 'Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage) | 2.3GHz Mediatek Helio G35 Octa core Processor',\n",
       " 'Oppo A31 (Fantasy White, 6GB RAM, 128GB Storage) with No Cost EMI/Additional Exchange Offers',\n",
       " 'Redmi 9 Power (Mighty Black, 6GB RAM, 128GB Storage) - 6000mAh Battery |FHD+ Screen| 48MP Quad Camera | Snapdragon 662 Processor | Alexa Hands-Free Capable',\n",
       " 'Samsung Galaxy M11 (Black, 4GB RAM, 64GB Storage) with No Cost EMI/Additional Exchange Offers',\n",
       " 'Samsung Galaxy M31 (Ocean Blue, 8GB RAM, 128GB Storage) 6 Months Free Screen Replacement for Prime',\n",
       " 'Redmi Note 9 (Pebble Grey, 4GB RAM 64GB Storage) - 48MP Quad Camera & Full HD+ Display',\n",
       " 'Redmi 9 Prime (Sunrise Flare, 4GB RAM, 64GB Storage)- Full HD+ Display & AI Quad Camera',\n",
       " 'Redmi 9 (Carbon Black, 4GB RAM, 64GB Storage) | 2.3GHz Mediatek Helio G35 Octa core Processor',\n",
       " 'Redmi Note 10 (Frost White, 4GB RAM, 64GB Storage) - Super Amoled Dot Display | 48MP Sony Sensor IMX582 | Snapdragon 678 Processor']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Product = []\n",
    "name = soup.find_all('span',class_=\"a-size-medium a-color-base a-text-normal\")\n",
    "\n",
    "for i in name[:10]:\n",
    "    Product.append(i.text)\n",
    "Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6,999',\n",
       " '8,999',\n",
       " '12,490',\n",
       " '13,499',\n",
       " '9,999',\n",
       " '16,999',\n",
       " '11,499',\n",
       " '9,999',\n",
       " '8,999',\n",
       " '12,999']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Price = []\n",
    "\n",
    "price = soup.find_all('span',class_=\"a-price-whole\")\n",
    "\n",
    "for i in price[:10]:\n",
    "    Price.append(i.text)\n",
    "Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://m.media-amazon.com/images/I/71sxlhYhKWL._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/71A9Vo1BatL._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/61CnyJ-IbML._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/61LHaUOhehL._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/710jkZNub3S._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/71-Su4Wr0HL._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/71X5I1cVfbL._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/71U2SiHgbiL._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/716nHhG9SWL._AC_UY218_.jpg',\n",
       " 'https://m.media-amazon.com/images/I/71SSmaLA7xS._AC_UY218_.jpg']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image = []\n",
    "\n",
    "url = soup.find_all('img',class_=\"s-image\")\n",
    "url\n",
    "\n",
    "for i in url[:10]:\n",
    "    Image.append(i.get('src'))\n",
    "Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.2 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.1 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.1 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.1 out of 5 stars',\n",
       " '4.1 out of 5 stars']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rating = []\n",
    "\n",
    "rating =soup.find_all('i',class_=\"a-icon a-icon-star-small a-star-small-4 aok-align-bottom\")\n",
    "\n",
    "for i in rating[:10]:\n",
    "    Rating.append(i.text)\n",
    "Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Image</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Redmi 9A (Nature Green, 2GB RAM, 32GB Storage)...</td>\n",
       "      <td>6,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71sxlhYhKW...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage) | 2....</td>\n",
       "      <td>8,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71A9Vo1Bat...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oppo A31 (Fantasy White, 6GB RAM, 128GB Storag...</td>\n",
       "      <td>12,490</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61CnyJ-IbM...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Redmi 9 Power (Mighty Black, 6GB RAM, 128GB St...</td>\n",
       "      <td>13,499</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61LHaUOheh...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsung Galaxy M11 (Black, 4GB RAM, 64GB Stora...</td>\n",
       "      <td>9,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/710jkZNub3...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Samsung Galaxy M31 (Ocean Blue, 8GB RAM, 128GB...</td>\n",
       "      <td>16,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71-Su4Wr0H...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Redmi Note 9 (Pebble Grey, 4GB RAM 64GB Storag...</td>\n",
       "      <td>11,499</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71X5I1cVfb...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Redmi 9 Prime (Sunrise Flare, 4GB RAM, 64GB St...</td>\n",
       "      <td>9,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71U2SiHgbi...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Redmi 9 (Carbon Black, 4GB RAM, 64GB Storage) ...</td>\n",
       "      <td>8,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/716nHhG9SW...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Redmi Note 10 (Frost White, 4GB RAM, 64GB Stor...</td>\n",
       "      <td>12,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71SSmaLA7x...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name   Price  \\\n",
       "0  Redmi 9A (Nature Green, 2GB RAM, 32GB Storage)...   6,999   \n",
       "1  Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage) | 2....   8,999   \n",
       "2  Oppo A31 (Fantasy White, 6GB RAM, 128GB Storag...  12,490   \n",
       "3  Redmi 9 Power (Mighty Black, 6GB RAM, 128GB St...  13,499   \n",
       "4  Samsung Galaxy M11 (Black, 4GB RAM, 64GB Stora...   9,999   \n",
       "5  Samsung Galaxy M31 (Ocean Blue, 8GB RAM, 128GB...  16,999   \n",
       "6  Redmi Note 9 (Pebble Grey, 4GB RAM 64GB Storag...  11,499   \n",
       "7  Redmi 9 Prime (Sunrise Flare, 4GB RAM, 64GB St...   9,999   \n",
       "8  Redmi 9 (Carbon Black, 4GB RAM, 64GB Storage) ...   8,999   \n",
       "9  Redmi Note 10 (Frost White, 4GB RAM, 64GB Stor...  12,999   \n",
       "\n",
       "                                               Image              Rating  \n",
       "0  https://m.media-amazon.com/images/I/71sxlhYhKW...  4.2 out of 5 stars  \n",
       "1  https://m.media-amazon.com/images/I/71A9Vo1Bat...  4.2 out of 5 stars  \n",
       "2  https://m.media-amazon.com/images/I/61CnyJ-IbM...  4.2 out of 5 stars  \n",
       "3  https://m.media-amazon.com/images/I/61LHaUOheh...  4.2 out of 5 stars  \n",
       "4  https://m.media-amazon.com/images/I/710jkZNub3...  4.1 out of 5 stars  \n",
       "5  https://m.media-amazon.com/images/I/71-Su4Wr0H...  4.2 out of 5 stars  \n",
       "6  https://m.media-amazon.com/images/I/71X5I1cVfb...  4.1 out of 5 stars  \n",
       "7  https://m.media-amazon.com/images/I/71U2SiHgbi...  4.2 out of 5 stars  \n",
       "8  https://m.media-amazon.com/images/I/716nHhG9SW...  4.1 out of 5 stars  \n",
       "9  https://m.media-amazon.com/images/I/71SSmaLA7x...  4.1 out of 5 stars  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['Product Name'] = Product\n",
    "df['Price'] = Price\n",
    "df['Image'] = Image\n",
    "df['Rating'] = Rating\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.8 Write a python program to extract information about the local weather from the National Weather Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the city. The data should include period, short description, temperature and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "page8 = requests.get('https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YQFxb0DhVPY')\n",
    "soup = BeautifulSoup(page8.content,'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tonight',\n",
       " 'Thursday',\n",
       " 'ThursdayNight',\n",
       " 'Friday',\n",
       " 'FridayNight',\n",
       " 'Saturday',\n",
       " 'SaturdayNight',\n",
       " 'Sunday',\n",
       " 'SundayNight']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period = []\n",
    "\n",
    "p1 = soup.find_all('p',class_=\"period-name\")\n",
    "\n",
    "for i in p1:\n",
    "    period.append(i.text)\n",
    "period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mostly Cloudy',\n",
       " 'Partly Sunnythen MostlySunny andBreezy',\n",
       " 'Partly Cloudyand Breezythen MostlyCloudy',\n",
       " 'Mostly Sunnythen Sunnyand Breezy',\n",
       " 'Partly Cloudyand Breezythen MostlyCloudy',\n",
       " 'Partly Sunny',\n",
       " 'Mostly Cloudy',\n",
       " 'Mostly Sunny',\n",
       " 'Partly Cloudy']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = []\n",
    "\n",
    "d1 = soup.find_all('p',class_=\"short-desc\")\n",
    "\n",
    "for i in d1:\n",
    "    desc.append(i.text)\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Low: 57 °F',\n",
       " 'Low: 56 °F',\n",
       " 'Low: 56 °F',\n",
       " 'Low: 56 °F',\n",
       " 'Low: 56 °F',\n",
       " 'High: 70 °F',\n",
       " 'High: 69 °F',\n",
       " 'High: 67 °F',\n",
       " 'High: 69 °F']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = []\n",
    "t1 = soup.find_all('p',class_=\"temp temp-low\")\n",
    "t2 = soup.find_all('p',class_=\"temp temp-high\")\n",
    "\n",
    "for i in t1:\n",
    "    temp.append(i.text)\n",
    "for i in t2:\n",
    "    temp.append(i.text)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Description</th>\n",
       "      <th>Temprature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tonight</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>Low: 57 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Partly Sunnythen MostlySunny andBreezy</td>\n",
       "      <td>Low: 56 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ThursdayNight</td>\n",
       "      <td>Partly Cloudyand Breezythen MostlyCloudy</td>\n",
       "      <td>Low: 56 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Mostly Sunnythen Sunnyand Breezy</td>\n",
       "      <td>Low: 56 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FridayNight</td>\n",
       "      <td>Partly Cloudyand Breezythen MostlyCloudy</td>\n",
       "      <td>Low: 56 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Partly Sunny</td>\n",
       "      <td>High: 70 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SaturdayNight</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>High: 69 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Mostly Sunny</td>\n",
       "      <td>High: 67 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SundayNight</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>High: 69 °F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Period                               Description   Temprature\n",
       "0        Tonight                             Mostly Cloudy   Low: 57 °F\n",
       "1       Thursday    Partly Sunnythen MostlySunny andBreezy   Low: 56 °F\n",
       "2  ThursdayNight  Partly Cloudyand Breezythen MostlyCloudy   Low: 56 °F\n",
       "3         Friday          Mostly Sunnythen Sunnyand Breezy   Low: 56 °F\n",
       "4    FridayNight  Partly Cloudyand Breezythen MostlyCloudy   Low: 56 °F\n",
       "5       Saturday                              Partly Sunny  High: 70 °F\n",
       "6  SaturdayNight                             Mostly Cloudy  High: 69 °F\n",
       "7         Sunday                              Mostly Sunny  High: 67 °F\n",
       "8    SundayNight                             Partly Cloudy  High: 69 °F"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Period'] = period\n",
    "data['Description'] = desc \n",
    "data['Temprature'] = temp\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.9 Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title, company name, CTC, and apply date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "page9 = requests.get('https://internshala.com/fresher-jobs')\n",
    "soup = BeautifulSoup(page9.content,'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sales Manager/Omni Sport Leader - Retail ',\n",
       " 'Business Development Executive ',\n",
       " 'Human Resources (HR) Associate/Counselor ',\n",
       " 'Junior iOS App Developer ',\n",
       " 'Software Testing Engineer ',\n",
       " 'Embedded Systems Associate ',\n",
       " 'Full Stack Developer ',\n",
       " 'Nutrition & Dietetics Specialist ',\n",
       " 'Human Resources (HR) Executive ',\n",
       " 'Junior Software Developer ',\n",
       " 'Business Development Manager ',\n",
       " 'Patent Research Associate ',\n",
       " 'Data Analyst ',\n",
       " 'Software Tester ',\n",
       " 'Business Development Executive ',\n",
       " 'MERN Stack Developer ',\n",
       " 'Conversion Rate Optimization Analyst ',\n",
       " 'Client Service Executive ',\n",
       " 'Sales Development Representative ',\n",
       " 'Corporate Sales Associate ',\n",
       " 'International Business Development Executive ',\n",
       " 'Product Marketer ',\n",
       " 'Customer Support Associates ',\n",
       " 'Content & Customer Care Executive ',\n",
       " 'Django Developer ',\n",
       " 'Reactjs Developer ',\n",
       " 'Web Development Trainee ',\n",
       " 'Business Development Executive ',\n",
       " 'Cybersecurity Compliance Officer ',\n",
       " 'MERN Stack Developer ',\n",
       " 'Senior Copywriter ',\n",
       " 'Corporate Sales Associate ',\n",
       " 'Digital Marketing Associate ',\n",
       " 'Social Media Marketing Executive ',\n",
       " 'Business Development Executive ',\n",
       " 'Operations Manager ',\n",
       " 'Lead Counselor ',\n",
       " 'Angular.js Developer ',\n",
       " 'Digital Marketing Specialist ',\n",
       " 'Franchise Manager - Sales (Assistant Manager ) ']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = []\n",
    "t1 = soup.find_all('div',class_=\"heading_4_5 profile\")\n",
    "\n",
    "for i in t1:\n",
    "    title.append(i.text.replace('\\n',''))\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Decathlon Sport India Private Limited',\n",
       " 'Velocity Media Networks',\n",
       " 'New Way Professionals Private Limited',\n",
       " 'Rang De',\n",
       " 'SafeSquid Labs',\n",
       " 'Signals & Systems India Private Limited',\n",
       " 'Wisestep',\n",
       " 'Nucros Science & Taste',\n",
       " 'Nikulsan Technologies Private Limited',\n",
       " 'Habitate Technologies Private Limited',\n",
       " 'School Of Excellence',\n",
       " 'Crimson Insights Technologies LLP',\n",
       " 'Anudeep Nekkanti',\n",
       " 'Startxlabs Technologies Private Limited',\n",
       " 'Padhhigh',\n",
       " 'Snippt',\n",
       " 'DataVinci Private Limited',\n",
       " 'Red Tree Design Studio Private Limited',\n",
       " 'HelloAR',\n",
       " 'Best Roadways Limited',\n",
       " 'Advids',\n",
       " 'Habitate Technologies Private Limited',\n",
       " 'Recruit CRM',\n",
       " 'Revo International LLP',\n",
       " 'Startxlabs Technologies Private Limited',\n",
       " 'Startxlabs Technologies Private Limited',\n",
       " 'Softsensor.ai',\n",
       " 'Verzeo',\n",
       " 'S3 Infosoft',\n",
       " 'Binary Numbers',\n",
       " 'Ranksoldier International Private Limited',\n",
       " 'MiM-Essay',\n",
       " 'BubbleNut Wash',\n",
       " 'Erikka India',\n",
       " 'Cosmic Micro Systems Private Limited',\n",
       " 'Kumi Labs',\n",
       " 'HOSS - House Of Soft Skills',\n",
       " 'Systaldyn Consultancy Private Limited',\n",
       " 'Sahadya Consultants',\n",
       " 'Regrob']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company = []\n",
    "\n",
    "name = soup.find_all('div',class_=\"heading_6 company_name\")\n",
    "\n",
    "for i in name:\n",
    "    company.append(i.text.replace('\\n','').strip())\n",
    "company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.3 - 4.5 LPA',\n",
       " '3 - 5 LPA',\n",
       " '3 - 4 LPA',\n",
       " '3 - 4.7 LPA',\n",
       " '3 LPA',\n",
       " '3 - 4 LPA',\n",
       " '3.25 - 5 LPA',\n",
       " '3 LPA',\n",
       " '3 LPA',\n",
       " '3.6 - 4.8 LPA',\n",
       " '3 - 3.5 LPA',\n",
       " '3 - 4 LPA',\n",
       " '6 - 10 LPA',\n",
       " '3 - 3.6 LPA',\n",
       " '4 - 7 LPA',\n",
       " '4 - 5 LPA',\n",
       " '5 LPA',\n",
       " '3 LPA',\n",
       " '3 - 3.2 LPA',\n",
       " '3 LPA',\n",
       " '3 - 4 LPA',\n",
       " '3.2 - 4.2 LPA',\n",
       " '5 - 7 LPA',\n",
       " '3 - 3.05 LPA',\n",
       " '3.5 - 7.5 LPA',\n",
       " '3.5 - 7.5 LPA',\n",
       " '3 - 5 LPA',\n",
       " '3 - 6 LPA',\n",
       " '3 - 3.6 LPA',\n",
       " '3 - 7 LPA',\n",
       " '3 LPA',\n",
       " '4.5 - 6 LPA',\n",
       " '3.6 - 5.4 LPA',\n",
       " '3 - 5 LPA',\n",
       " '3 - 4.8 LPA',\n",
       " '3 - 8 LPA',\n",
       " '3.8 - 4.5 LPA',\n",
       " '3 - 5 LPA',\n",
       " '3 - 3.5 LPA',\n",
       " '3 - 3.1 LPA']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = []\n",
    "CTC = []\n",
    "\n",
    "c1 = soup.find_all('div',class_=\"item_body\")\n",
    "\n",
    "for i in c1:\n",
    "    info.append(i.text.strip().replace('\\n',''))\n",
    "    \n",
    "for i in range(1,len(info),3):\n",
    "    CTC.append(info[i])\n",
    "CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"21 Aug' 21\",\n",
       " \"28 Aug' 21\",\n",
       " \"27 Aug' 21\",\n",
       " \"27 Aug' 21\",\n",
       " \"27 Aug' 21\",\n",
       " \"27 Aug' 21\",\n",
       " \"27 Aug' 21\",\n",
       " \"27 Aug' 21\",\n",
       " \"27 Aug' 21\",\n",
       " \"27 Aug' 21\",\n",
       " \"27 Aug' 21\",\n",
       " \"27 Aug' 21\",\n",
       " \"27 Aug' 21\",\n",
       " \"27 Aug' 21\",\n",
       " \"26 Aug' 21\",\n",
       " \"26 Aug' 21\",\n",
       " \"26 Aug' 21\",\n",
       " \"26 Aug' 21\",\n",
       " \"26 Aug' 21\",\n",
       " \"26 Aug' 21\",\n",
       " \"26 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"23 Aug' 21\",\n",
       " \"23 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"23 Aug' 21\",\n",
       " \"23 Aug' 21\",\n",
       " \"22 Aug' 21\",\n",
       " \"25 Aug' 21\",\n",
       " \"22 Aug' 21\",\n",
       " \"22 Aug' 21\",\n",
       " \"22 Aug' 21\",\n",
       " \"22 Aug' 21\"]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dinfo = []\n",
    "date = []\n",
    "\n",
    "d1 = soup.find_all('div',class_=\"item_body\")\n",
    "\n",
    "for i in d1:\n",
    "    dinfo.append(i.text.strip().replace('\\n',''))\n",
    "    \n",
    "for i in range(2,len(dinfo),3):\n",
    "    date.append(dinfo[i])\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Apply Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sales Manager/Omni Sport Leader - Retail</td>\n",
       "      <td>Decathlon Sport India Private Limited</td>\n",
       "      <td>3.3 - 4.5 LPA</td>\n",
       "      <td>21 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Velocity Media Networks</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>28 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human Resources (HR) Associate/Counselor</td>\n",
       "      <td>New Way Professionals Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>27 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Junior iOS App Developer</td>\n",
       "      <td>Rang De</td>\n",
       "      <td>3 - 4.7 LPA</td>\n",
       "      <td>27 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Software Testing Engineer</td>\n",
       "      <td>SafeSquid Labs</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>27 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Embedded Systems Associate</td>\n",
       "      <td>Signals &amp; Systems India Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>27 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Wisestep</td>\n",
       "      <td>3.25 - 5 LPA</td>\n",
       "      <td>27 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nutrition &amp; Dietetics Specialist</td>\n",
       "      <td>Nucros Science &amp; Taste</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>27 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Human Resources (HR) Executive</td>\n",
       "      <td>Nikulsan Technologies Private Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>27 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Junior Software Developer</td>\n",
       "      <td>Habitate Technologies Private Limited</td>\n",
       "      <td>3.6 - 4.8 LPA</td>\n",
       "      <td>27 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Business Development Manager</td>\n",
       "      <td>School Of Excellence</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>27 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Patent Research Associate</td>\n",
       "      <td>Crimson Insights Technologies LLP</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>27 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Anudeep Nekkanti</td>\n",
       "      <td>6 - 10 LPA</td>\n",
       "      <td>27 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Software Tester</td>\n",
       "      <td>Startxlabs Technologies Private Limited</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>27 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Padhhigh</td>\n",
       "      <td>4 - 7 LPA</td>\n",
       "      <td>26 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MERN Stack Developer</td>\n",
       "      <td>Snippt</td>\n",
       "      <td>4 - 5 LPA</td>\n",
       "      <td>26 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Conversion Rate Optimization Analyst</td>\n",
       "      <td>DataVinci Private Limited</td>\n",
       "      <td>5 LPA</td>\n",
       "      <td>26 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Client Service Executive</td>\n",
       "      <td>Red Tree Design Studio Private Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>26 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sales Development Representative</td>\n",
       "      <td>HelloAR</td>\n",
       "      <td>3 - 3.2 LPA</td>\n",
       "      <td>26 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Corporate Sales Associate</td>\n",
       "      <td>Best Roadways Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>26 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>International Business Development Executive</td>\n",
       "      <td>Advids</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>26 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Product Marketer</td>\n",
       "      <td>Habitate Technologies Private Limited</td>\n",
       "      <td>3.2 - 4.2 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Customer Support Associates</td>\n",
       "      <td>Recruit CRM</td>\n",
       "      <td>5 - 7 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Content &amp; Customer Care Executive</td>\n",
       "      <td>Revo International LLP</td>\n",
       "      <td>3 - 3.05 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Django Developer</td>\n",
       "      <td>Startxlabs Technologies Private Limited</td>\n",
       "      <td>3.5 - 7.5 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Reactjs Developer</td>\n",
       "      <td>Startxlabs Technologies Private Limited</td>\n",
       "      <td>3.5 - 7.5 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Web Development Trainee</td>\n",
       "      <td>Softsensor.ai</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Verzeo</td>\n",
       "      <td>3 - 6 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cybersecurity Compliance Officer</td>\n",
       "      <td>S3 Infosoft</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MERN Stack Developer</td>\n",
       "      <td>Binary Numbers</td>\n",
       "      <td>3 - 7 LPA</td>\n",
       "      <td>23 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Senior Copywriter</td>\n",
       "      <td>Ranksoldier International Private Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>23 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Corporate Sales Associate</td>\n",
       "      <td>MiM-Essay</td>\n",
       "      <td>4.5 - 6 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Digital Marketing Associate</td>\n",
       "      <td>BubbleNut Wash</td>\n",
       "      <td>3.6 - 5.4 LPA</td>\n",
       "      <td>23 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Social Media Marketing Executive</td>\n",
       "      <td>Erikka India</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>23 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Cosmic Micro Systems Private Limited</td>\n",
       "      <td>3 - 4.8 LPA</td>\n",
       "      <td>22 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Operations Manager</td>\n",
       "      <td>Kumi Labs</td>\n",
       "      <td>3 - 8 LPA</td>\n",
       "      <td>25 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Lead Counselor</td>\n",
       "      <td>HOSS - House Of Soft Skills</td>\n",
       "      <td>3.8 - 4.5 LPA</td>\n",
       "      <td>22 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Angular.js Developer</td>\n",
       "      <td>Systaldyn Consultancy Private Limited</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>22 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Digital Marketing Specialist</td>\n",
       "      <td>Sahadya Consultants</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>22 Aug' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Franchise Manager - Sales (Assistant Manager )</td>\n",
       "      <td>Regrob</td>\n",
       "      <td>3 - 3.1 LPA</td>\n",
       "      <td>22 Aug' 21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job Title  \\\n",
       "0         Sales Manager/Omni Sport Leader - Retail    \n",
       "1                   Business Development Executive    \n",
       "2         Human Resources (HR) Associate/Counselor    \n",
       "3                         Junior iOS App Developer    \n",
       "4                        Software Testing Engineer    \n",
       "5                       Embedded Systems Associate    \n",
       "6                             Full Stack Developer    \n",
       "7                 Nutrition & Dietetics Specialist    \n",
       "8                   Human Resources (HR) Executive    \n",
       "9                        Junior Software Developer    \n",
       "10                    Business Development Manager    \n",
       "11                       Patent Research Associate    \n",
       "12                                    Data Analyst    \n",
       "13                                 Software Tester    \n",
       "14                  Business Development Executive    \n",
       "15                            MERN Stack Developer    \n",
       "16            Conversion Rate Optimization Analyst    \n",
       "17                        Client Service Executive    \n",
       "18                Sales Development Representative    \n",
       "19                       Corporate Sales Associate    \n",
       "20    International Business Development Executive    \n",
       "21                                Product Marketer    \n",
       "22                     Customer Support Associates    \n",
       "23               Content & Customer Care Executive    \n",
       "24                                Django Developer    \n",
       "25                               Reactjs Developer    \n",
       "26                         Web Development Trainee    \n",
       "27                  Business Development Executive    \n",
       "28                Cybersecurity Compliance Officer    \n",
       "29                            MERN Stack Developer    \n",
       "30                               Senior Copywriter    \n",
       "31                       Corporate Sales Associate    \n",
       "32                     Digital Marketing Associate    \n",
       "33                Social Media Marketing Executive    \n",
       "34                  Business Development Executive    \n",
       "35                              Operations Manager    \n",
       "36                                  Lead Counselor    \n",
       "37                            Angular.js Developer    \n",
       "38                    Digital Marketing Specialist    \n",
       "39  Franchise Manager - Sales (Assistant Manager )    \n",
       "\n",
       "                                      Company            CTC  Apply Date  \n",
       "0       Decathlon Sport India Private Limited  3.3 - 4.5 LPA  21 Aug' 21  \n",
       "1                     Velocity Media Networks      3 - 5 LPA  28 Aug' 21  \n",
       "2       New Way Professionals Private Limited      3 - 4 LPA  27 Aug' 21  \n",
       "3                                     Rang De    3 - 4.7 LPA  27 Aug' 21  \n",
       "4                              SafeSquid Labs          3 LPA  27 Aug' 21  \n",
       "5     Signals & Systems India Private Limited      3 - 4 LPA  27 Aug' 21  \n",
       "6                                    Wisestep   3.25 - 5 LPA  27 Aug' 21  \n",
       "7                      Nucros Science & Taste          3 LPA  27 Aug' 21  \n",
       "8       Nikulsan Technologies Private Limited          3 LPA  27 Aug' 21  \n",
       "9       Habitate Technologies Private Limited  3.6 - 4.8 LPA  27 Aug' 21  \n",
       "10                       School Of Excellence    3 - 3.5 LPA  27 Aug' 21  \n",
       "11          Crimson Insights Technologies LLP      3 - 4 LPA  27 Aug' 21  \n",
       "12                           Anudeep Nekkanti     6 - 10 LPA  27 Aug' 21  \n",
       "13    Startxlabs Technologies Private Limited    3 - 3.6 LPA  27 Aug' 21  \n",
       "14                                   Padhhigh      4 - 7 LPA  26 Aug' 21  \n",
       "15                                     Snippt      4 - 5 LPA  26 Aug' 21  \n",
       "16                  DataVinci Private Limited          5 LPA  26 Aug' 21  \n",
       "17     Red Tree Design Studio Private Limited          3 LPA  26 Aug' 21  \n",
       "18                                    HelloAR    3 - 3.2 LPA  26 Aug' 21  \n",
       "19                      Best Roadways Limited          3 LPA  26 Aug' 21  \n",
       "20                                     Advids      3 - 4 LPA  26 Aug' 21  \n",
       "21      Habitate Technologies Private Limited  3.2 - 4.2 LPA  25 Aug' 21  \n",
       "22                                Recruit CRM      5 - 7 LPA  25 Aug' 21  \n",
       "23                     Revo International LLP   3 - 3.05 LPA  25 Aug' 21  \n",
       "24    Startxlabs Technologies Private Limited  3.5 - 7.5 LPA  25 Aug' 21  \n",
       "25    Startxlabs Technologies Private Limited  3.5 - 7.5 LPA  25 Aug' 21  \n",
       "26                              Softsensor.ai      3 - 5 LPA  25 Aug' 21  \n",
       "27                                     Verzeo      3 - 6 LPA  25 Aug' 21  \n",
       "28                                S3 Infosoft    3 - 3.6 LPA  25 Aug' 21  \n",
       "29                             Binary Numbers      3 - 7 LPA  23 Aug' 21  \n",
       "30  Ranksoldier International Private Limited          3 LPA  23 Aug' 21  \n",
       "31                                  MiM-Essay    4.5 - 6 LPA  25 Aug' 21  \n",
       "32                             BubbleNut Wash  3.6 - 5.4 LPA  23 Aug' 21  \n",
       "33                               Erikka India      3 - 5 LPA  23 Aug' 21  \n",
       "34       Cosmic Micro Systems Private Limited    3 - 4.8 LPA  22 Aug' 21  \n",
       "35                                  Kumi Labs      3 - 8 LPA  25 Aug' 21  \n",
       "36                HOSS - House Of Soft Skills  3.8 - 4.5 LPA  22 Aug' 21  \n",
       "37      Systaldyn Consultancy Private Limited      3 - 5 LPA  22 Aug' 21  \n",
       "38                        Sahadya Consultants    3 - 3.5 LPA  22 Aug' 21  \n",
       "39                                     Regrob    3 - 3.1 LPA  22 Aug' 21  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame()\n",
    "df['Job Title'] = title\n",
    "df['Company'] = company\n",
    "df['CTC'] = CTC\n",
    "df['Apply Date'] = date\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.10 Write a python program to scrape house details from https://www.nobroker.in/ for any location. It should include house title, location, area, emi and price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "page10 = requests.get('https://www.nobroker.in/property/sale/pune/multiple?searchParam=W3sibGF0IjoxOC41Njc5MTQ2LCJsb24iOjczLjkxNDM0MzE5OTk5OTk5LCJwbGFjZUlkIjoiQ2hJSnRZUVU1a2JCd2pzUnNMTzBxUGNzU0xZIiwicGxhY2VOYW1lIjoiVmltYW4gTmFnYXIifSx7ImxhdCI6MTguNTQxOCwibG9uIjo3My45MjIzODY1LCJwbGFjZUlkIjoiQ2hJSlVVUDFMSGZCd2pzUnRkdUZ4RVo2dkxRIiwicGxhY2VOYW1lIjoiTmV3IEthbHlhbmkgTmFnYXIifSx7ImxhdCI6MTguNTA4NjQyOSwibG9uIjo3My44MzE0MDkxLCJwbGFjZUlkIjoiQ2hJSndfQnlYNHVfd2pzUmVwc1U0Z3RNX3drIiwicGxhY2VOYW1lIjoiRXJhbmR3YW5lIn1d&radius=2.0')\n",
    "soup = BeautifulSoup(page10.content,'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 BHK Flat  For Sale  In Brahmacorp F Residences Phase Ii In New Kalyani Nagar ',\n",
       " '2 BHK Flat  For Sale  In Brahmacorp F Residences Phase Ii, Kalyani Nagar In Bramha Corp Resale & Rental ',\n",
       " '1 BHK Flat  For Sale  In Water Bay In Vadgaon Sheri ',\n",
       " '1 BHK Apartment  For Sale  In Water Bay In Vadgaon Sheri ',\n",
       " '1 RK Flat  For Sale  In Bhairavnath Temple Vadgaonsheri Pune In Wadgaon Sheri ',\n",
       " '2 BHK Flat  For Sale  In Bhoomi Heights In Wadgaon Sheri ',\n",
       " '1 BHK Flat  For Sale  In Wadgaon Sheri, ',\n",
       " '2 BHK Flat  For Sale  In Jp Paradise In Wadgaonsheri ',\n",
       " '1 BHK Flat  For Sale  In Madhav Apartment In Wadgaonsheri ',\n",
       " '1 BHK Flat  For Sale  In Ap In Wadgaonsheri ']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = []\n",
    "t1 = soup.find_all('h2',class_=\"heading-6 font-semi-bold nb__1AShY\")\n",
    "\n",
    "for i in t1:\n",
    "    title.append(i.text)\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vadgaon sheri',\n",
       " 'Wadgaonsheri Road ',\n",
       " 'Inamdar School Rd, Digambar Nagar, Near The Farm Fresh',\n",
       " 'Water Bay\\xa0 New Kalyani Nagar, Vitthal Nagar, Digambar Nagar,, New Kalyani Nagar, Vitthal Nagar, Digambar Nagar, Vadgaon Sheri, Pune, Maharashtra 411014, India',\n",
       " 'bhairavnath mandir',\n",
       " 'Dhanvantari Colony Opp Lonkar Madhyamik & Uchamadhyamik Vidyalaya',\n",
       " 'Standalone Building,  Navratna Housing Society, Vitthal Nagar, Digambar Nagar Near Suryamukhi Ganesh Temple',\n",
       " 'near post office,opposite to telephone exchange wadgaonsheri pune',\n",
       " 'Post Office',\n",
       " 'wadgaonsheri']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location =[]\n",
    "\n",
    "l1 = soup.find_all('div',class_=\"nb__2CMjv\")\n",
    "\n",
    "for i in l1:\n",
    "    location.append(i.text)\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹31,522/Month',\n",
       " '₹67,631/Month',\n",
       " '₹34,388/Month',\n",
       " '₹31,522/Month',\n",
       " '₹8,597/Month',\n",
       " '₹40,120/Month',\n",
       " '₹13,755/Month',\n",
       " '₹29,803/Month',\n",
       " '₹15,474/Month',\n",
       " '₹15,474/Month']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emiinfo = []\n",
    "emi = []\n",
    "e1 = soup.find_all('div',class_=\"font-semi-bold heading-6\")\n",
    "\n",
    "for i in e1:\n",
    "    emiinfo.append(i.text)\n",
    "emiinfo\n",
    "\n",
    "\n",
    "for i in range(1,len(emiinfo),3):\n",
    "    emi.append(emiinfo[i])\n",
    "emi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹55 Lacs',\n",
       " '₹1.18 Crores',\n",
       " '₹60 Lacs',\n",
       " '₹55 Lacs',\n",
       " '₹15 Lacs',\n",
       " '₹70 Lacs',\n",
       " '₹24 Lacs',\n",
       " '₹52 Lacs',\n",
       " '₹27 Lacs',\n",
       " '₹27 Lacs']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priceinfo = []\n",
    "price = []\n",
    "p1 = soup.find_all('div',class_=\"font-semi-bold heading-6\")\n",
    "\n",
    "for i in p1:\n",
    "    priceinfo.append(i.text)\n",
    "priceinfo\n",
    "\n",
    "\n",
    "for i in range(2,len(priceinfo),3):\n",
    "    price.append(priceinfo[i])\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>House Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>EMi</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 BHK Flat  For Sale  In Brahmacorp F Residenc...</td>\n",
       "      <td>vadgaon sheri</td>\n",
       "      <td>₹31,522/Month</td>\n",
       "      <td>₹55 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 BHK Flat  For Sale  In Brahmacorp F Residenc...</td>\n",
       "      <td>Wadgaonsheri Road</td>\n",
       "      <td>₹67,631/Month</td>\n",
       "      <td>₹1.18 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 BHK Flat  For Sale  In Water Bay In Vadgaon ...</td>\n",
       "      <td>Inamdar School Rd, Digambar Nagar, Near The Fa...</td>\n",
       "      <td>₹34,388/Month</td>\n",
       "      <td>₹60 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 BHK Apartment  For Sale  In Water Bay In Vad...</td>\n",
       "      <td>Water Bay  New Kalyani Nagar, Vitthal Nagar, D...</td>\n",
       "      <td>₹31,522/Month</td>\n",
       "      <td>₹55 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 RK Flat  For Sale  In Bhairavnath Temple Vad...</td>\n",
       "      <td>bhairavnath mandir</td>\n",
       "      <td>₹8,597/Month</td>\n",
       "      <td>₹15 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2 BHK Flat  For Sale  In Bhoomi Heights In Wad...</td>\n",
       "      <td>Dhanvantari Colony Opp Lonkar Madhyamik &amp; Ucha...</td>\n",
       "      <td>₹40,120/Month</td>\n",
       "      <td>₹70 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1 BHK Flat  For Sale  In Wadgaon Sheri,</td>\n",
       "      <td>Standalone Building,  Navratna Housing Society...</td>\n",
       "      <td>₹13,755/Month</td>\n",
       "      <td>₹24 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2 BHK Flat  For Sale  In Jp Paradise In Wadgao...</td>\n",
       "      <td>near post office,opposite to telephone exchang...</td>\n",
       "      <td>₹29,803/Month</td>\n",
       "      <td>₹52 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1 BHK Flat  For Sale  In Madhav Apartment In W...</td>\n",
       "      <td>Post Office</td>\n",
       "      <td>₹15,474/Month</td>\n",
       "      <td>₹27 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1 BHK Flat  For Sale  In Ap In Wadgaonsheri</td>\n",
       "      <td>wadgaonsheri</td>\n",
       "      <td>₹15,474/Month</td>\n",
       "      <td>₹27 Lacs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         House Title  \\\n",
       "0  1 BHK Flat  For Sale  In Brahmacorp F Residenc...   \n",
       "1  2 BHK Flat  For Sale  In Brahmacorp F Residenc...   \n",
       "2  1 BHK Flat  For Sale  In Water Bay In Vadgaon ...   \n",
       "3  1 BHK Apartment  For Sale  In Water Bay In Vad...   \n",
       "4  1 RK Flat  For Sale  In Bhairavnath Temple Vad...   \n",
       "5  2 BHK Flat  For Sale  In Bhoomi Heights In Wad...   \n",
       "6           1 BHK Flat  For Sale  In Wadgaon Sheri,    \n",
       "7  2 BHK Flat  For Sale  In Jp Paradise In Wadgao...   \n",
       "8  1 BHK Flat  For Sale  In Madhav Apartment In W...   \n",
       "9       1 BHK Flat  For Sale  In Ap In Wadgaonsheri    \n",
       "\n",
       "                                            Location            EMi  \\\n",
       "0                                      vadgaon sheri  ₹31,522/Month   \n",
       "1                                 Wadgaonsheri Road   ₹67,631/Month   \n",
       "2  Inamdar School Rd, Digambar Nagar, Near The Fa...  ₹34,388/Month   \n",
       "3  Water Bay  New Kalyani Nagar, Vitthal Nagar, D...  ₹31,522/Month   \n",
       "4                                 bhairavnath mandir   ₹8,597/Month   \n",
       "5  Dhanvantari Colony Opp Lonkar Madhyamik & Ucha...  ₹40,120/Month   \n",
       "6  Standalone Building,  Navratna Housing Society...  ₹13,755/Month   \n",
       "7  near post office,opposite to telephone exchang...  ₹29,803/Month   \n",
       "8                                        Post Office  ₹15,474/Month   \n",
       "9                                       wadgaonsheri  ₹15,474/Month   \n",
       "\n",
       "          Price  \n",
       "0      ₹55 Lacs  \n",
       "1  ₹1.18 Crores  \n",
       "2      ₹60 Lacs  \n",
       "3      ₹55 Lacs  \n",
       "4      ₹15 Lacs  \n",
       "5      ₹70 Lacs  \n",
       "6      ₹24 Lacs  \n",
       "7      ₹52 Lacs  \n",
       "8      ₹27 Lacs  \n",
       "9      ₹27 Lacs  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd = pd.DataFrame()\n",
    "\n",
    "hd['House Title'] = title\n",
    "hd['Location']= location\n",
    "hd['EMi'] =  emi\n",
    "hd['Price'] = price\n",
    "\n",
    "hd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
