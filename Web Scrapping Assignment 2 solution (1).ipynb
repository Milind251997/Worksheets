{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  WEB SCRAPING ASSIGNMENT 2 SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Some Necessery libraries\n",
    "import selenium\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up firefox web-driver\n",
    "driver = webdriver.Firefox(executable_path = 'geckodriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name,experience_required. You have to scrape first 10 jobs data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting url\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send keys to job search as 'Data Analyst'\n",
    "search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys('Data Analyst')\n",
    "\n",
    "#fill location field and send keys\n",
    "search_loc = driver.find_element_by_id('qsb-location-sugg')\n",
    "search_loc.send_keys('Bangalore')\n",
    "\n",
    "#Press enter button\n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Scrape job title using xpath\n",
    "jobs_title = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_title = []\n",
    "\n",
    "for i in jobs_title[:10]:\n",
    "    job_title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Product/Data Analyst - SQL/Tableau/Qlikview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Process Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst II - Customer Support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst _ 2-5 Years _ Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Product Data Analyst - IT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Job Title\n",
       "0                                 Data Analyst\n",
       "1                                 Data Analyst\n",
       "2  Product/Data Analyst - SQL/Tableau/Qlikview\n",
       "3                                 Data Analyst\n",
       "4                                 Data Analyst\n",
       "5                         Process Data Analyst\n",
       "6                                 Data Analyst\n",
       "7           Data Analyst II - Customer Support\n",
       "8         Data Analyst _ 2-5 Years _ Bangalore\n",
       "9                    Product Data Analyst - IT"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Dataframe\n",
    "df = pd.DataFrame()\n",
    "df['Job Title'] = job_title\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location,company_name, full job-description. You have to scrape first 10 jobs data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Url\n",
    "page = driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill job search field and send keys\n",
    "job_search = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "job_search.send_keys('Data Scientist')\n",
    "\n",
    "#Fill location search field and send keys\n",
    "loc_search = driver.find_element_by_id('qsb-location-sugg')\n",
    "loc_search.send_keys('Bangalore')\n",
    "\n",
    "#Press Search Button\n",
    "btn = driver.find_element_by_class_name('btn')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title = []#empty list \n",
    "Location = []#empty list \n",
    "Name =  []#empty list \n",
    "\n",
    "#Find elments \n",
    "title = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "location = driver.find_elements_by_xpath('//i[@class=\"fleft icon-16 lh16 mr-4 naukicon naukicon-location\"]')\n",
    "comp_name = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "for i in title:\n",
    "    Title.append(i.text)\n",
    "time.sleep(5)#Scrape Titles \n",
    "\n",
    "for i in location:\n",
    "    Location.append(i.text)\n",
    "time.sleep(5)#scrape location\n",
    "\n",
    "for i in comp_name:\n",
    "    Name.append(i.text)\n",
    "time.sleep(5)#scrape company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-senior-data-scientist-symbiosis-international-w-l-l-bangalore-bengaluru-10-to-15-years-050821004331?src=jobsearchDesk&sid=16282471906477142&xp=1&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-datamatics-global-services-ltd-bangalore-bengaluru-8-to-13-years-040821003517?src=jobsearchDesk&sid=16282471906477142&xp=2&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-mcafee-software-india-pvt-ltd-bangalore-bengaluru-4-to-8-years-050821501145?src=jobsearchDesk&sid=16282471906477142&xp=3&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-engineers-data-scientist-and-sap-teamware-solutions-bangalore-bengaluru-7-to-10-years-300721500677?src=jobsearchDesk&sid=16282471906477142&xp=4&px=1',\n",
       " 'https://www.naukri.com/job-listings-python-data-scientist-mindtree-limited-bangalore-bengaluru-3-to-5-years-040821500207?src=jobsearchDesk&sid=16282471906477142&xp=5&px=1',\n",
       " 'https://www.naukri.com/job-listings-software-developer-data-scientist-nlp-machine-learning-dot-net-cunesoft-india-private-limited-bangalore-bengaluru-3-to-8-years-190121001281?src=jobsearchDesk&sid=16282471906477142&xp=6&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-uber-bangalore-bengaluru-6-to-8-years-050821500683?src=jobsearchDesk&sid=16282471906477142&xp=7&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-associate-data-scientist-novotree-minds-consulting-pvt-limited-bangalore-bengaluru-4-to-7-years-300721001832?src=jobsearchDesk&sid=16282471906477142&xp=8&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-ibm-india-pvt-limited-bangalore-bengaluru-5-to-10-years-260721907182?src=jobsearchDesk&sid=16282471906477142&xp=9&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-publicis-groupe-bangalore-bengaluru-2-to-5-years-030821501259?src=jobsearchDesk&sid=16282471906477142&xp=10&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-bidgely-technologies-private-limited-bangalore-bengaluru-4-to-6-years-030821500043?src=jobsearchDesk&sid=16282471906477142&xp=11&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-goals-101-data-solutions-pvt-ltd-new-delhi-bangalore-bengaluru-delhi-ncr-4-to-8-years-030821000870?src=jobsearchDesk&sid=16282471906477142&xp=12&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-permanent-role-onward-technologies-limited-hyderabad-secunderabad-chennai-bangalore-bengaluru-6-to-11-years-030821002780?src=jobsearchDesk&sid=16282471906477142&xp=13&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-randstad-india-pvt-ltd-bangalore-bengaluru-4-to-9-years-280721000424?src=jobsearchDesk&sid=16282471906477142&xp=14&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-red-hat-india-pvt-ltd-bangalore-bengaluru-8-to-13-years-220721008125?src=jobsearchDesk&sid=16282471906477142&xp=15&px=1',\n",
       " 'https://www.naukri.com/job-listings-sr-data-scientist-tech-lead-data-science-confidential-bangalore-bengaluru-6-to-9-years-020821903704?src=jobsearchDesk&sid=16282471906477142&xp=16&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-l-a-consultancy-kochi-cochin-hyderabad-secunderabad-pune-chennai-delhi-ncr-bangalore-bengaluru-5-to-9-years-310721903849?src=jobsearchDesk&sid=16282471906477142&xp=17&px=1',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-tensorflow-machine-learning-getinz-techno-services-mumbai-hyderabad-secunderabad-chennai-bangalore-bengaluru-7-to-10-years-250721900474?src=jobsearchDesk&sid=16282471906477142&xp=18&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-analyst-data-scientist-naukri-employer-services-bangalore-bengaluru-1-to-4-years-300721006074?src=jobsearchDesk&sid=16282471906477142&xp=19&px=1',\n",
       " 'https://www.naukri.com/job-listings-associate-data-scientist-execboardinasia-bangalore-bengaluru-5-to-10-years-310721500675?src=jobsearchDesk&sid=16282471906477142&xp=20&px=1']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_des_urls = []#empty list\n",
    "\n",
    "#getting url's from page\n",
    "url = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "for i in url:\n",
    "    job_des_urls.append(i.get_attribute('href'))\n",
    "job_des_urls #Scrape url's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Required Candidate profileWe are looking for a Senior Data Scientist with a min of 10 years experience in Banking Financial Domain (especially Compliance related) and a solid background in Cloudera.As a Cloudera Specialist, you must be adept in Cloudera tools like CDH, CEPH, CM, CMA, Data node EDH, HVE, JAS, NameNode, Nodemanager, QJM, QJN, RM and ZK.This will be a two years assignment to one of the Leading Class A banks in Abu Dhabi.Candidate should have finished two or three full implementations of Data Analytics in Compliance in large Enterprise Banks.Should be having thorough knowledge in R, Python, Scala on demand and Jupyter Notebooks.Should be having hands experience in CCA Spark and Hadoop developer.Should be having a Financial Compliance Background with a good knowledge and hands on expertise on Compliance related domains.Should be a Machine Learning expert and create new models and use various library in that area. You should have proven skills in this area.Should be having a thorough theoretical and practical idea on the following systems (From a Data Scientist Perspective)HDFSYarnMapReduceHivePigApache AmbariHBase / Apache ImpalaStormOozieRangerZookeeperVarious data ingestion tools like Sqoop, flume, KafkaVarious reporting tools like Drill, Phoenix, ZeppelinWill be an added advantage if you have exposure to GPU processing, Tensor Flow and Data Lakes.Should be able to produce high Quality Business documentation, Project Management, Agile Framework practices as needed.Should inspect the current Cloudera Architecture and suggest enhancements or improve it.Should be able to communicate with Senior Business Management ideas, concepts and deliverables.If you have certifications on Cloudera (Cloudera Data Engineer, Spark and Hadoop Developer), it will be an added advantage.Data Scientist - ComplianceResponsibilities:Use advanced analytics methods to extract value from business dataPerform large-scale experimentation and build data-driven models to answer business questionsConduct research on cutting-edge techniques and tools in machine learning/deep learning/artificial intelligenceDetermine requirements that will be used to train and evolve deep learning models and algorithmsArticulate a vision and roadmap for the exploitation of data as a valued corporate assetInfluence product teams through presentation of data-based recommendationsEvangelize best practices to analytics and products teamsAssemble large, complex data sets that meet functional / non-functional business requirements.Identify, design, and implement internal process improvements: automating manual processes, optimizing analytics delivery, re-designing infrastructure for greater scalability, etc.Build analytics tools that utilize the data to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.Work with stakeholders including the Executive, Product, Data and Design teams to assist with analytics related technical issues and support their data infrastructure needs.Work with data and analytics experts to strive for greater functionality data systemsTypical skills and background:SKILLS:Can work with data to identify patterns.Use judgement to form conclusions that may challenge conventional wisdom and focus on the crux of issues to identify high-leverage intervention points and strategies.Rapidly acquire new knowledge and learn new skillsSeek to understand business needs and get results that have a clear, positive, and direct impact on business performanceApply different strategies to convince others to change their opinions or plans and ensure that proposals or arguments are supported by strong logic and a compelling business case, addressing all relevant factors.Consider the relative costs and benefits of potential actions to choose the most appropriate oneCommunication and storytellingTeamwork and collaborationBanking domain business knowledgeAdvanced analytics modelling and orchestrationSolid development skills in Java, Scala and SQLSound knowledge of using data science tools and languages like Cloudera Data Science Workbench (CDSW), Jupyter Notebook, Python etc.Clear hands-on mastery in big datab systems - Hadoop ecosystem, Cloud technologies (AWS, Azure, Google), in-memory database systems (HANA, Hazel cast, etc) and other database systems - traditional RDBMS (Terradata, SQL Server, Oracle), and NoSQL databases (Cassandra, MongoDB, DynamoDB)Comfortable in dashboard development (Tableau, Powerbi, Qlik, etc) and in developing data analytics models (R, Python, Spark)EXPERIENCE AND QUALIFICATION:Masters degree from top-tier college/university in Computer Science, Statistics, Economics, or other closely-related fieldMinimum of 6 years' hands-on experience with a strong data backgroundExtensive experience working with Big Data tools and building data solutions for advanced analyticsExperience with statistical software, scripting languages, and packages (e.g. R, MATLAB, SAS, and Python)Considerable experience in solving business problems with advanced analytical solutionsProven experience in conducting statistical analysis and building models with advanced scripting language such as R, SPSS, or other analytic tools.Experience building and deploying predictive models, web scraping, and scalable data pipelines.Strong understanding of statistical methods and skills such as Bayesian Networks Inference, linear and non-linear regression, hierarchical, mixed models/multi-level modelingPractical knowledge across data extraction and transformation tools - traditional ETL tools (Informatica, Altryx) as well as more recent big data toolsFinancial Renumeration will be based on your skills and expertise.Notice Period of 30 to 45 days preferredPrevious working experience in Middle East and Gulf regions preferred Roles and ResponsibilitiesDesired Candidate ProfilePerks and Benefits\",\n",
       " 'Roles and ResponsibilitiesDetails in lined for Hiring Team to focus:The hiring is for a single Data Scientist (7-8+yrs) as he/she shall be an individual contributor.We shall seek for a strong java/python/scala with expertise into frameworks ML (spark/keras/tensorflow).ML concepts has to be thorough with proven expertise in ( Decision Trees, Random Forest, NLP) Deep Learning is excluded.Desired Candidate ProfilePerks and Benefits',\n",
       " 'Data Scientist Primary Location India, Bangalore Date posted 08/01/2021Apply Now Save Job ID: JR0024575Job Title:Data ScientistRole Overview:Data scientist will be doing research on innovative projects in platform engineering group at McAfee. Platform Engineering Group is the is one of the core groups responsible for collecting data from millions of sensors from various products of Enterprises, using the data to protect the customers, provide insights and necessary actions to be taken for security gap.This position is an integral part of the McAfee Enterprise business segment which was acquired by Symphony Technology Group (STG) in July 2021. McAfee Enterprise and its team members remain committed to keeping governments and enterprises safe. This position is dedicated to and part of the McAfee Enterprise business.Company OverviewMcAfee is a leader in personal security for consumers. Focused on protecting people, not just devices, McAfee consumer solutions adapt to users needs in an always online world, empowering them to live securely through integrated, intuitive solutions that protects their families and communities with the right security at the right moment.About the Role:Develop Machine learning models to analyze and obtain practical insights from large volume of data that requires expertise at data exploration, analysis and feature engineeringExperiment and Develop POCs of innovative ideas to come up with new solutions for addressing security gapsCreate machine learning pipelines to automate generation of efficient and better modelsCommunicate and work with engineering teams to productionize the solutionsTaking ownership and responsibility of the solutions and driving to closureParticipate in data and product analytics to develop customer insights and product featuresImplement newer machine learning algorithms and models to improve the efficacy of the existing solutionsPublish research papers on the experiments and machine learning solutionsAbout you :5+ years of experience in the field of Data Science5+ years of programming experience in at least one of Python or Java3+ years of working experience on large datasets using ML and experience with ML model life cyclePhD degree in Computer Science, Data Science, Statistics, Mathematics or other related fields is preferredDeep knowledge in Natural Language processing, Deep learning, statistics, predictive modeling and time series analysis.Passionate about Cybersecurity and want to apply machine learning solutions in this space to solve security problems.Experience working on Big data problemsExperience working on problems relevant to detecting risk, fraud and trust is an added advantageExperience in working in AWS cloud environment is an added advantageExperience with Publishing research papers',\n",
       " 'Dynamic recruiting professional with 7 - 10 years of high-performance tech recruiting experience with search firms and /or mid-large-sized technology companies.Experience in engaging and hiring the best talent for Data Engineers, Data Scientist and SAPOpen to learning from your peers managers, anything that helps you do your job better day in day out also often share best practices in hiring talent attraction strategies with them.Work well with teams as also on your own as a high-impact individual contributor.Use social media, job boards, Internet sourcing, and other technical means to source candidates for open jobs.Understanding of modern recruiting methods like hackathons but are equally comfortable with old school methods as well.Work with internal technology teams and hiring managers to assist with recruitment efforts across levels.Work in sync with the company-wide recruitment strategy. This may include job posting optimization, recruiting marketing channel development, search selection using job boards, digital and non-digital employment marketing, comprehensive recruitment campaign planning, talent planning, stakeholder management, etc.Identify and source appropriate talent for current open roles within the organization using traditional non-traditional means of recruiting.Proactively develop talent pools/talent communities to dip into when hiring is in full swing.Manage the end-to-end recruitment process and life-cycle, including sourcing, initial assessments, telephonic personal interviews culminating in offers maintaining the appropriate MIS.',\n",
       " 'Basic Qualifications3-5 years of hands-on experience in in data science, applied statistics, machine learning, data mining, statistical modeling tools and underlying algorithms 3-5 years of hands-on experience building production grade machine learning enabled solutions end to end.3-5 years of experience in statistical modeling methods, time series, text mining, optimization, information retrieval3-5 years hands-on experience using R, Python or and other languages appropriate for large scale analysis of numerical and textual data3-5 years Hands-on experience using SQL and data miningExperience with experiments, machine learning, deep learning, anomaly detection, predictive analysis, exploratory data analysis, and other areas of data scienceExperience using large data systems Advanced data visualization experienceExperience in business, program and/or strategy planning Experience in business, program and/or strategy planning Experience in business, program and/or strategy planning.Job Requirements:Python, SQL, R Language, Machine Learning for Rules, AI Hub, Machine Learning Fundamentals, Machine Learning Application',\n",
       " 'Dear CandidatesWe are looking for a competent and enthusiastic candidate with the below requirement. This vital role ensures Cunesoft India Pvt Ltd (a Phlexglobal Company) Bangalore can provide a high-quality end product to internal and external users. This position requires strong technical and communication skills as well as both independent and team working, including working closely with all other areas of the software delivery team and the rest of the Technology department.Roles and ResponsibilitiesKey ActivitiesDevelop and improve the existing data mining and NLP related processes within our Regulatory Data Management platformDevelop new ways of improving and transforming the regulatory processes of Phlexglobal customers.Interact with product management, project management and development teams to develop additional modules and functions within the Phlexglobal Cloud PlatformDesign and create solutions for pre specified modules and functionsUse existing tools and techniques to develop and test new and existing workDefine, create and execute automated test cases, i.e. unit testsParticipate in troubleshooting and triaging of issues with different teams to drive towards root cause identification and resolutionSupport production deployment of applications and perform validation testing during the off-hours maintenance windowsSupport and fix existing and new identified issues by either customers or internal test teams.Desired Candidate ProfileRequired Skills & ExperienceMinimum 3+ years working experience in NLP, Artificial Intelligence, Machine Learning, Text Mining, Neural NetworksStrong programming skills using PYTHONIn depth experience with OpenNLP, Stanford NLP or related NLP / data mining technologiesIn depth experience with Python and data libraries such as scikit learn, pandas, numpy, etc.Selecting features, building and optimizing classifiers using Machine learning techniquesExcellent understanding of Machine Learning Techniques and Algorithms.Must have Data mining / Natural Language Processing experienceMust have very good understanding of GITProcessing, Cleansing, and verifying the integrity of dataDevelop custom data models and algorithms to apply to data sets.Defining validation strategiesDefining the preprocessing or feature engineering to be done on a given datasetDefining data augmentation pipelinesTraining models and tuning their hyperparametersAnalyzing the errors of the model and designing strategies to overcome themDeploying models to productionAdded advantages3+ years experience using Microsoft .NET / C#Exposure to ML.Net, AutoML, NimbusML, etcGood knowledge of Microsoft Visual Studio is preferredGood to have Microsoft SQL Server, preferably Microsoft SQL AzurePrevious experience in the Life sciences areaOther requirementsExcellent verbal and written communication skillsMust be flexible, independent and self motivatedPunctual, Regular and consistent attendanceAs part of the Interview process, you should have attempted the below mentioned Kaggle project.https://www.kaggle.com/c/titanicWe would like to arrange a phone interview with you. Please confirm your interest in this position by sending your recent CV attached along with below details.Total years of Experience :Relevant Experience :Current CTC :Expected CTC :Notice Period :Current Location :Best time to talk to you :Candidates with relevant experience can contact me.We are looking for a candidate who can join us immediately / in less than 15-20 days / 30 days / ASAPPlease ignore, if you have already been interviewed within 3 months.ThanksSrinisarumugam@phlexglobal.com+91 63660 85842Dot Net DeveloperJunior (3-5 yrs), Mid (5-8 yrs) & Lead (8-12 yrs) level roles.Commercial experience in web development using the full Microsoft .Net development stack (specifically C#, MVC, .Net Core), SQL, front-end frameworks (jQuery, React, etc).Coding, Entity framework, Linq, Source control system (Any - TFS or GIT), Data structuresSkilled in modern development principles (Agile, SOLID, TDD, design patterns, IoC)At least theoretical knowledge - know-SQL database (exampleAzure Cosmos)Good to have - Ideally experience of Azure, MVVM, microservices, message bus, containerisation, serverless.Microsoft .Net development stack, C#, MVC, .Net Core, SQL, front-end frameworks, jQuery, React, Entity framework, Linq, TFS, GIT, Data structures, Agile, SOLID, TDD, design patterns, IoC, SQL database, Azure Cosmos, Azure, MVVM, microservices, message bus, containerisation, serverless',\n",
       " \"About the roleWe are looking for skilled motivated professionals who will support and own multiple projects globally that drive business growth while still balancing compliance risk and partner friction. The role will cover areas such as (not limited to) Sanctions screening; Partner and user compliance; Customer due diligence; Transaction monitoring; Metrics development and monitoring; and Model and Strategy development - to help balance partner friction and compliance riskWhat you'll doDevelop and manage user risk rating models that meet applicable regulatory requirements and are aligned with standard methodologies and practices. Interpret large amounts of complex data to formulate problem statements, concise conclusions regarding underlying risk dynamics, trends, and opportunities Identify key risk indicators and metrics while developing and monitoring key parameters, enhance reporting, and identify new areas of analytic focus to better understand operational risk.Own compliance specific area - end to end - ranging from the discovery of the business problem to eventually working with the Engineering/Product teams to execute it Strategy design and analysis of domain-specific use-cases such as Reduction of cost of compliance;Improve monitoring mechanism to alert any anomaly in compliance or business metric; Improve funnel for Partner onboarding, thereby improving user experience; and Drive multiple experiments to evaluate and quantify the hypothesis Extensive data analytics and SQL query writing Predictive modeling / Machine learning algorithms - using random Forest / Decision tree / Logistic regressionKey Qualifications6 years of proven experience in a data-focused role such as product analytics, business analytics, business operations, or data science Education in Engineering, Computer Science, Math, Economics, Statistics or equivalent experience Past experience in Payments or Compliance with a Product / Tech company serving millions of customers on multiple platforms and countries BA/BS in Mathematics, Statistics, Computer Science, Economics, Business or analytical field SQL mastery.Write efficient and complex code in SQL Experience in Python/R and in experimentation, A/B testing, and statistical modeling Define business metrics, including Key Performance Indicators, for financial products, in close partnership with Product Management and other leaders Proven ability to handle large datasets, explore and utilize raw data feedsExcellent data visualization skills Love of data - you just go get the data you need and turn it into an insightful story. You know how to convert data into decisions without getting stuck in paralysis by analysis A well-organized, structured approach to problem-solvingStrong sense of ownership, accountability, and entrepreneurial spirit Able to lead change and solution-oriented Great communicator, problem-solver confident in decision making Independent autonomous, while still a strong teammate Enthusiastic, self-starting and thrives in changing, agile environment.\",\n",
       " 'Roles and ResponsibilitiesAs a Senior Associate you will be responsible for the overall health of a client engagement. You will be challenged with a mix of technical as well as business strategy/planning problems. As a key member of the team, you will be expected to drive adoption of new technologies, tools and process improvements within the team to build world class analytical capabilities for customers.Primary Responsibilities:Ability to work with business users to refine analytical requirements and breakdown/solvecomplex business problemsStaying connected with analytics industry trends in data, techniques, technologies and leveragingthem to develop learning packages as well as evangelizing their use across teamsDepending on the client engagement, leading a team of analysts/associates and mentoring people in a fast paced, learning driven environmentStrong application knowledge of tools (R/SAS/Python/SPSS etc.)Hands on experience in statistical techniques (Regression, Machine Learning, Classification, Time series, etc.)Experience of working on analytics projects and initiatives with 5+ years of experienceAdditional Responsibilities:Proficiency with GitUnderstanding of software development methodologies (Agile essential), values, and proceduresExperience or certifications with visualization tools (Tableau/Qlik/PowerBI etc.)Well versed with big data handling using Hadoop, etc.Project management certifications: PMP/ CAPM/ CSMDesired Candidate ProfilePerks and Benefits',\n",
       " '-',\n",
       " 'Work location: Bengaluru (Currently, Remote)Shift timing: 12PM to 9PMWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.Develop a use case roadmap for a problem area or capability for the business. Frame the business problem into a Data Science or modelling problem.Extract data from multiple sources. Mine and analyze data from company databases to drive optimization and improvement of product.Work as the data strategist, identifying and integrating new datasets that can be leveraged through our product capabilities and work closely with Client Support, Product Management and Engineering team to strategize and execute the development of data products.Processing, cleansing, and verifying the integrity of data used for analysis. Undertake preprocessing of structured and unstructured data.Data mining using state-of-the-art methods. Selecting features, building and optimizing classifiers using ML/AI techniques.Present technical solutions to internal and external stakeholders in a formal setting, effectively communicating key concepts and functionalitiesEffectively manage client expectations via direct and frequent communication with high quality resultsDevelop front end deliverable solutions for stakeholders utilizing BI tools such as Tableau, Cognos, Excel, or similarWork on multiple assignments concurrently, while handling priorities and challenges and meeting timelines basis project plan and roadmap.Build self-service tools for error detection, diagnosis, and predictive metrics.Build project plans, maintain to-do list, organize work, follow coding ethics, and have an eye for detailQualificationsBachelor s or Master s degree in a quantitative discipline (e.g., data science, statistics, economics, mathematics, computer science) or significant relevant coursework/experience4+ years professional experience in the field of data science or business intelligenceDemonstrated proficiency in PYTHON/SCALA/SQL and BIG DATA technologies and the proven ability to program in big data/cloud technologies such as AWS SPARK; minimum 3 years of experienceExperienced with Machine Learning algorithms such as logistic regression, linear regression, lasso regression, k-means, random forest, XG boost, KNN, SVM and neural network; minimum 2 years of experienceAble to produce elaborate documents/narrative suggesting actionable insights and recommendations leveraging BI tools such as TableauExpertise with Microsoft Office products; including Excel, PowerPoint, WordGreat communication skills. Excellent written and verbal communication skills for coordinating across teams.Self-driven and results oriented. Willing to stretch to meet tight timelines.Strong team player with ability to collaborate effectively across geographies/ time zonesGood understanding of Digital Marketing, Campaign Measurement, Web AnalyticsDesirable Qualifications:Professional experience working with RProfessional experience working with Power BI, Cognos, Dash, Looker, DomoProfessional experience in fraud analytics, customer journey, attribution modeling, churn modeling, predictive analytics, customer segmentation, feature creation, statistical testing, a/b testing, production curve modeling, NLP, and partner recommendations.Professional analytical consulting experience with clients in Retail, Finance, Travel, or Home and Business Services']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_desc = []#empty list \n",
    "\n",
    "for i in job_des_urls[:10]:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        description = driver.find_element_by_xpath('//section[@class=\"job-desc\"]/div[1]')\n",
    "        job_desc.append(description.text.replace('\\n',''))\n",
    "    except:\n",
    "        job_desc.append('-')\n",
    "job_desc #Scrape job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Job description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td>SYMBIOSIS International W.L.L</td>\n",
       "      <td>Required Candidate profileWe are looking for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td>Datamatics Global Services Ltd</td>\n",
       "      <td>Roles and ResponsibilitiesDetails in lined for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td></td>\n",
       "      <td>McAfee Software (India) Pvt. Ltd</td>\n",
       "      <td>Data Scientist Primary Location India, Bangalo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineers , Data Scientist and SAP</td>\n",
       "      <td></td>\n",
       "      <td>Teamware Solutions</td>\n",
       "      <td>Dynamic recruiting professional with 7 - 10 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python - Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td>Mindtree Limited</td>\n",
       "      <td>Basic Qualifications3-5 years of hands-on expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Software Developer - Data Scientist / NLP / Ma...</td>\n",
       "      <td></td>\n",
       "      <td>Cunesoft India Private Limited</td>\n",
       "      <td>Dear CandidatesWe are looking for a competent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data scientist</td>\n",
       "      <td></td>\n",
       "      <td>Uber</td>\n",
       "      <td>About the roleWe are looking for skilled motiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Associate - Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td>Novotree Minds Consulting Pvt Limited</td>\n",
       "      <td>Roles and ResponsibilitiesAs a Senior Associat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>Work location: Bengaluru (Currently, Remote)Sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Location  \\\n",
       "0                              Senior Data Scientist            \n",
       "1                              Senior Data Scientist            \n",
       "2                                     DATA SCIENTIST            \n",
       "3            Data Engineers , Data Scientist and SAP            \n",
       "4                            Python - Data Scientist            \n",
       "5  Software Developer - Data Scientist / NLP / Ma...            \n",
       "6                                     Data scientist            \n",
       "7                  Senior Associate - Data Scientist            \n",
       "8                              Senior Data Scientist            \n",
       "9                              Senior Data Scientist            \n",
       "\n",
       "                                 Company  \\\n",
       "0          SYMBIOSIS International W.L.L   \n",
       "1         Datamatics Global Services Ltd   \n",
       "2       McAfee Software (India) Pvt. Ltd   \n",
       "3                     Teamware Solutions   \n",
       "4                       Mindtree Limited   \n",
       "5         Cunesoft India Private Limited   \n",
       "6                                   Uber   \n",
       "7  Novotree Minds Consulting Pvt Limited   \n",
       "8                 IBM India Pvt. Limited   \n",
       "9                        Publicis Groupe   \n",
       "\n",
       "                                     Job description  \n",
       "0  Required Candidate profileWe are looking for a...  \n",
       "1  Roles and ResponsibilitiesDetails in lined for...  \n",
       "2  Data Scientist Primary Location India, Bangalo...  \n",
       "3  Dynamic recruiting professional with 7 - 10 ye...  \n",
       "4  Basic Qualifications3-5 years of hands-on expe...  \n",
       "5  Dear CandidatesWe are looking for a competent ...  \n",
       "6  About the roleWe are looking for skilled motiv...  \n",
       "7  Roles and ResponsibilitiesAs a Senior Associat...  \n",
       "8                                                  -  \n",
       "9  Work location: Bengaluru (Currently, Remote)Sh...  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create DataFrame\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Title'] = Title[:10]\n",
    "df['Location'] = Location[:10]\n",
    "df['Company'] = Name[:10]\n",
    "df['Job description'] = job_desc[:10]\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: In this question you have to scrape data using the filters available on the  webpage as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting url\n",
    "page2 = driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fill job search field and send keys\n",
    "job_search = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "job_search.send_keys('Data Scientist')\n",
    "\n",
    "#Click search button\n",
    "search_btn = driver.find_element_by_class_name('btn')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter location 'Delhi'\n",
    "f_loc = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[3]/label/i')\n",
    "f_loc.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter salary '3-6 lakhs'\n",
    "f_salary =  driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/i')\n",
    "f_salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Immediate Openings For DATA Scientist with 6 To 7 yrs of Experience',\n",
       " 'Data Scientist/Data Analyst /Business Analyst',\n",
       " 'Senior Data Scientist - Noida',\n",
       " 'Data Scientist / Data Analyst',\n",
       " 'Only Fresher / Data Scientist / Data Analyst / Analytics - MNC Jobs',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist - Machine Learning/NLP',\n",
       " 'Data Scientist - Machine Learning/NLP']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find elments\n",
    "job = driver.find_elements_by_xpath(\"//a[@class = 'title fw500 ellipsis']\")\n",
    "\n",
    "job_titles = []#empty list \n",
    "\n",
    "for i in job[:10]:\n",
    "    job_titles.append(i.text)\n",
    "job_titles\n",
    "#scrape job titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Immediate Openings For DATA Scientist with 6 T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Data Analyst /Business Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist - Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Machine Learning/NLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Machine Learning/NLP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job Titles\n",
       "0  Immediate Openings For DATA Scientist with 6 T...\n",
       "1      Data Scientist/Data Analyst /Business Analyst\n",
       "2                      Senior Data Scientist - Noida\n",
       "3                      Data Scientist / Data Analyst\n",
       "4  Only Fresher / Data Scientist / Data Analyst /...\n",
       "5                                     Data Scientist\n",
       "6                              Senior Data Scientist\n",
       "7                                     Data Scientist\n",
       "8              Data Scientist - Machine Learning/NLP\n",
       "9              Data Scientist - Machine Learning/NLP"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Dataframe\n",
    "df = pd.DataFrame()\n",
    "df['Job Titles'] = job_titles\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting url\n",
    "page3 = driver.get('https://www.glassdoor.co.in/index.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click sign in button\n",
    "sign_in = driver.find_element_by_xpath(\"/html/body/div[2]/div/div/div/div/div[1]/article/header/nav/div[2]/div/div/div/button\").click()\n",
    "time.sleep(3)\n",
    "\n",
    "#mail for sign in\n",
    "mail = driver.find_element_by_xpath('//*[@id=\"userEmail\"]')\n",
    "mail.send_keys('milinr58@gmail.com')\n",
    "time.sleep(2)\n",
    "\n",
    "#password\n",
    "passw = driver.find_element_by_xpath('//*[@id=\"userPassword\"]')\n",
    "passw.send_keys('Glasor@123')\n",
    "time.sleep(2)\n",
    "\n",
    "#click enter button\n",
    "btn = driver.find_element_by_xpath('/html/body/div[8]/div/div/div[2]/div[2]/div[2]/div/div/div/div[3]/form/div[3]/div[1]/button').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill job search field \n",
    "job_search = driver.find_element_by_xpath('//*[@id=\"sc.keyword\"]')\n",
    "job_search.send_keys('Data Scientist')\n",
    "\n",
    "#fill location search field\n",
    "loc_search = driver.find_element_by_xpath('//*[@id=\"sc.location\"]')\n",
    "loc_search.clear()\n",
    "time.sleep(2)\n",
    "loc_search.send_keys('Noida')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click search button\n",
    "btn = driver.find_element_by_xpath('/html/body/header/nav[1]/div/div/div/div[4]/div[2]/form/div/button')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = []#empty list \n",
    "days = []#empty list \n",
    "\n",
    "#Find elments\n",
    "comp_name = driver.find_elements_by_xpath('//a[@class=\" css-l2wjgv e1n63ojh0 jobLink\"]')\n",
    "days_ago = driver.find_elements_by_xpath('//div[@class=\"d-flex align-items-end pl-std css-mi55ob\"]')\n",
    "rating = driver.find_elements_by_xpath('//span[@class=\"css-19pjha7 e1cjmv6j1\"]')\n",
    "\n",
    "for i in comp_name[:10]:\n",
    "    company.append(i.text) #scrape company name\n",
    "\n",
    "for j in days_ago[:10]:\n",
    "    days.append(j.text) #scrape description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = []#empty list \n",
    "for k in rating:\n",
    "    ratings.append(k.text)\n",
    "#scrape ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liberin Technologies Private Limited</td>\n",
       "      <td>10d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pixel Vision</td>\n",
       "      <td>21d</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Trained Education</td>\n",
       "      <td>24h</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crowe</td>\n",
       "      <td>30d+</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newgen Software</td>\n",
       "      <td>21d</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>5d</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td></td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Uncodemy</td>\n",
       "      <td>1d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Company Duration Rating\n",
       "0  Liberin Technologies Private Limited      10d    3.8\n",
       "1                          Pixel Vision      21d    3.3\n",
       "2                Data Trained Education      24h    4.1\n",
       "3                                 Crowe     30d+    4.1\n",
       "4                       Newgen Software      21d    5.0\n",
       "5          Salasar New Age Technologies     30d+    4.1\n",
       "6                              Ericsson       5d    3.1\n",
       "7                        Biz2Credit Inc             3.8\n",
       "8                              Techlive     30d+    3.8\n",
       "9                              Uncodemy       1d    3.7"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['Company'] = company[:10]\n",
    "df['Duration'] = days[:10]\n",
    "df['Rating'] = ratings[:10]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "## You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting url\n",
    "page4 = driver.get('https://www.glassdoor.co.in/Salaries/index.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill job search field \n",
    "job_search = driver.find_element_by_id('KeywordSearch')\n",
    "job_search.send_keys('Data Scientist')\n",
    "\n",
    "#clear the location field\n",
    "driver.find_element_by_id('LocationSearch').clear()\n",
    "\n",
    "#fill location search field\n",
    "loc_search = driver.find_element_by_id('LocationSearch')\n",
    "loc_search.send_keys('Noida')\n",
    "\n",
    "#click search button\n",
    "btn = driver.find_element_by_id('HeroSearchButton')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is an window coming for filling a review or salary to the website called glassdoor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "#### 1. Brand\n",
    "#### 2. Product Description\n",
    "#### 3. Price\n",
    "#### 4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting url\n",
    "page5 = driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill product search field\n",
    "pro_search = driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "pro_search.send_keys('sunglasses')\n",
    "time.sleep(2)\n",
    "\n",
    "#click search button\n",
    "btn = driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []#empty list \n",
    "description = []#empty list \n",
    "price =[]#empty list \n",
    "discount = []#empty list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_name = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_name:\n",
    "    brand.append(i.text)\n",
    "time.sleep(3) #scrape brand name\n",
    "\n",
    "desc = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "for j in desc:\n",
    "    description.append(j.text)\n",
    "time.sleep(3) #scrape description\n",
    "\n",
    "pro_price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "for k in pro_price:\n",
    "    price.append(k.text)\n",
    "time.sleep(3) #scrape product price\n",
    " \n",
    "pro_discount = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "for l in pro_discount:\n",
    "    discount.append(l.text)\n",
    "time.sleep(5) #scrape product discount\n",
    "\n",
    "next_b = driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "next_b.click() #click next button for next page\n",
    "time.sleep(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_name = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_name:\n",
    "    brand.append(i.text)  #scrape brand name\n",
    "time.sleep(3)\n",
    "\n",
    "desc = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "for j in desc:\n",
    "    description.append(j.text) #scrape description\n",
    "time.sleep(3)\n",
    "\n",
    "pro_price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "for k in pro_price:\n",
    "    price.append(k.text) #scrape product price\n",
    "time.sleep(3)\n",
    "\n",
    "pro_discount = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "for l in pro_discount:\n",
    "    discount.append(l.text) #scrape product discount\n",
    "\n",
    "next_b = driver.find_element_by_xpath('/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]')\n",
    "next_b.click() #click next button for next page\n",
    "time.sleep(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_name = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_name:\n",
    "    brand.append(i.text) #scrape brand name\n",
    "time.sleep(3)\n",
    "\n",
    "desc = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "for j in desc:\n",
    "    description.append(j.text) #scrape description\n",
    "time.sleep(3)\n",
    "\n",
    "pro_price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "for k in pro_price:\n",
    "    price.append(k.text #scrape product price\n",
    "time.sleep(3)\n",
    "\n",
    "pro_discount = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "for l in pro_discount:\n",
    "    discount.append(l.text) #scrape product discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Specification</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAMIW COLLECTION</td>\n",
       "      <td>UV Protection Wayfarer, Sports, Shield, Rectan...</td>\n",
       "      <td>₹199</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wrogn</td>\n",
       "      <td>Mirrored Wayfarer Sunglasses (51)</td>\n",
       "      <td>₹739</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹295</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>25% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹699</td>\n",
       "      <td>22% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (58)</td>\n",
       "      <td>₹274</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (60)</td>\n",
       "      <td>₹349</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹474</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Round Sunglasses (Free Size)</td>\n",
       "      <td>₹380</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                                      Specification Price  \\\n",
       "0   HAMIW COLLECTION  UV Protection Wayfarer, Sports, Shield, Rectan...  ₹199   \n",
       "1              Wrogn                  Mirrored Wayfarer Sunglasses (51)  ₹739   \n",
       "2          Elligator                UV Protection Round Sunglasses (54)  ₹295   \n",
       "3           Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹599   \n",
       "4           Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹699   \n",
       "..               ...                                                ...   ...   \n",
       "95             NuVew          UV Protection Rectangular Sunglasses (58)  ₹274   \n",
       "96    kingsunglasses              UV Protection Cat-eye Sunglasses (60)  ₹349   \n",
       "97        PHENOMENAL  Gradient, UV Protection Wayfarer Sunglasses (F...  ₹379   \n",
       "98         ROYAL SON       UV Protection Aviator Sunglasses (Free Size)  ₹474   \n",
       "99             NuVew         UV Protection Round Sunglasses (Free Size)  ₹380   \n",
       "\n",
       "   Discount  \n",
       "0   86% off  \n",
       "1   71% off  \n",
       "2   88% off  \n",
       "3   25% off  \n",
       "4   22% off  \n",
       "..      ...  \n",
       "95  82% off  \n",
       "96  78% off  \n",
       "97  81% off  \n",
       "98  68% off  \n",
       "99  73% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['Brand'] = brand[:100]\n",
    "df['Specification'] =description[:100]\n",
    "df['Price'] = price[:100]\n",
    "df['Discount'] = discount[:100]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting url\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click show all reviews\n",
    "driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div/div/div[5]/div/a/div/span').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = []#empty list \n",
    "review = []#empty list \n",
    "f_review = []#empty list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find elments\n",
    "ratings = driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "reviews = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "f_reviews = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "\n",
    "for i in ratings:\n",
    "    rating.append(i.text) #scrape  ratings\n",
    "time.sleep(2) \n",
    "\n",
    "for j in reviews:\n",
    "    review.append(j.text) #scrape reviews\n",
    "time.sleep(2) \n",
    "\n",
    "for k in f_reviews:\n",
    "    f_review.append(k.text) #scrape full Reviews\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url= []#empty list \n",
    "urls = driver.find_elements_by_xpath('//a[@class=\"ge-49M\"]')\n",
    "\n",
    "for i in urls:\n",
    "    url.append(i.get_attribute('href')) #get reviews\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        ratings = driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "        for i in ratings:\n",
    "            rating.append(i.text)\n",
    "    except:\n",
    "        rating.append('--') #scrape ratings from all url's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url:\n",
    "    driver.get(i)\n",
    "    reviews = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "    f_reviews = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "    \n",
    "    for j in reviews:\n",
    "        review.append(j.text)  #scrape reviews from all url's\n",
    "        time.sleep(3)\n",
    "    for k in f_reviews:\n",
    "        f_review.append(k.text) #scrape full reviews from all url's\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Short review</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Here is the thing\\n\\nThe only reason why you s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Undoubtedly Iphone 11 is the most successful m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>If you are looking for a premium phone under 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>I purchased the iPhone 11 a month back. I must...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>We are on apple ecosystem for almost eight yea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Short review  \\\n",
       "0       5     Simply awesome   \n",
       "1       5          Brilliant   \n",
       "2       5   Perfect product!   \n",
       "3       5          Fabulous!   \n",
       "4       5  Worth every penny   \n",
       "..    ...                ...   \n",
       "95      4  Worth every penny   \n",
       "96      5  Worth every penny   \n",
       "97      5       Nice product   \n",
       "98      5          Fabulous!   \n",
       "99      5     Classy product   \n",
       "\n",
       "                                               Review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   This is my first iOS phone. I am very happy wi...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  Here is the thing\\n\\nThe only reason why you s...  \n",
       "96  Undoubtedly Iphone 11 is the most successful m...  \n",
       "97  If you are looking for a premium phone under 5...  \n",
       "98  I purchased the iPhone 11 a month back. I must...  \n",
       "99  We are on apple ecosystem for almost eight yea...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['Rating'] = rating[:100]\n",
    "df['Short review'] = review[:100]\n",
    "df['Review'] = f_review[:100]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.You have to scrape 4 attributes of each sneaker :\n",
    "#### 1. Brand\n",
    "#### 2. Product Description\n",
    "#### 3. Price\n",
    "#### 4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting url\n",
    "page7 = driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill up search field \n",
    "search = driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "search.send_keys('sneakers')\n",
    "\n",
    "#click search button\n",
    "btn = driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []#empty list \n",
    "desc = []#empty list \n",
    "price = []#empty list \n",
    "discount = []#empty list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find elments\n",
    "brand_name = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "description = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "pro_price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "disc = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "\n",
    "for i in brand_name:\n",
    "    brand.append(i.text) #scrape brand name\n",
    "time.sleep(3)\n",
    "for i in description:\n",
    "    desc.append(i.text) #scrape description\n",
    "time.sleep(3)\n",
    "for i in pro_price:\n",
    "    price.append(i.text) #scrape product price\n",
    "time.sleep(3)\n",
    "for i in disc:\n",
    "    discount.append(i.text) #scrape discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=2',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=3',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=4',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=5',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=6',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=7',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=8',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=9',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=10']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = []#empty list \n",
    "url = driver.find_elements_by_xpath('//a[@class=\"ge-49M\"]')\n",
    "for i in url:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "urls #scrape next page url's from the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls[:2]:\n",
    "    driver.get(i) #get elements \n",
    "    brand_name = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "    description = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "    pro_price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    disc = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "\n",
    "    for i in brand_name:\n",
    "        brand.append(i.text) #scrape brand name from url's\n",
    "    time.sleep(3)\n",
    "    for i in description:\n",
    "        desc.append(i.text) #scrape description from url's\n",
    "    time.sleep(3)\n",
    "    for i in pro_price:\n",
    "        price.append(i.text) #scrape product price from url's\n",
    "    time.sleep(3)\n",
    "    for i in disc:\n",
    "        discount.append(i.text) #scrape discount from url's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,289</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bata</td>\n",
       "      <td>CASIO Sneakers For Men</td>\n",
       "      <td>₹1,048</td>\n",
       "      <td>38% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>Original Luxury Branded Fashionable Men's Casu...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Unique &amp; Perfect Collection Combo Pack of 02 S...</td>\n",
       "      <td>₹420</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹356</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Wrogn</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,059</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Classic Sneakers For Men</td>\n",
       "      <td>₹474</td>\n",
       "      <td>59% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Flex Renew SlipOn Sneakers For Men</td>\n",
       "      <td>₹407</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>Casual , Partywear Sneakers Shoes For Men's An...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>SB FC STANDARD Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product Description   Price  \\\n",
       "0           DUCATI                                   Sneakers For Men  ₹1,289   \n",
       "1             Bata                             CASIO Sneakers For Men  ₹1,048   \n",
       "2         ASTEROID  Original Luxury Branded Fashionable Men's Casu...    ₹499   \n",
       "3           Chevit  Unique & Perfect Collection Combo Pack of 02 S...    ₹420   \n",
       "4         Magnolia                                   Sneakers For Men    ₹356   \n",
       "..             ...                                                ...     ...   \n",
       "95           Wrogn                                   Sneakers For Men  ₹1,059   \n",
       "96    Robbie jones                           Classic Sneakers For Men    ₹474   \n",
       "97         Numenzo                 Flex Renew SlipOn Sneakers For Men    ₹407   \n",
       "98  luxury fashion  Casual , Partywear Sneakers Shoes For Men's An...    ₹379   \n",
       "99  luxury fashion                    SB FC STANDARD Sneakers For Men    ₹399   \n",
       "\n",
       "   Discount  \n",
       "0   65% off  \n",
       "1   38% off  \n",
       "2   75% off  \n",
       "3   71% off  \n",
       "4   64% off  \n",
       "..      ...  \n",
       "95  52% off  \n",
       "96  59% off  \n",
       "97  87% off  \n",
       "98  69% off  \n",
       "99  60% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Dataframe\n",
    "df= pd.DataFrame()\n",
    "\n",
    "df['Brand'] = brand[:100]\n",
    "df['Product Description'] = desc[:100]\n",
    "df['Price'] = price[:100]\n",
    "df['Discount'] = discount[:100]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q.9 Go to the link - https://www.myntra.com/shoes And then scrape First 100 shoes data you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting url\n",
    "page8 = driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter price “Rs. 6649 to Rs. 13099”\n",
    "price_filter = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div').click()\n",
    "time.sleep(5)\n",
    "#filter colour to black\n",
    "colour_filter = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []#empty list \n",
    "desc = []#empty list\n",
    "price = []#empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find elments\n",
    "brandname = driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "description = driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "pprice = driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "\n",
    "for i in brandname:\n",
    "    brand.append(i.text) #scrape brand name\n",
    "time.sleep(3)\n",
    "for i in description:\n",
    "    desc.append(i.text) #scrape description\n",
    "time.sleep(3)\n",
    "for i in pprice:\n",
    "    price.append(i.text.strip) #scrape product price\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click next button\n",
    "next_b = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[12]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "brandname = driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]') #scrape elements \n",
    "description = driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "pprice = driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "\n",
    "for i in brandname:\n",
    "    brand.append(i.text) #scrape brand name\n",
    "time.sleep(3)\n",
    "for i in description:\n",
    "    desc.append(i.text) #scrape description\n",
    "time.sleep(3)\n",
    "for i in pprice:\n",
    "    price.append(i.text) #scrape product price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Driving Shoes</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>LEBRON XVIII Basketball Shoes</td>\n",
       "      <td>Rs. 11436Rs. 17595(35% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Textured Leather Loafers</td>\n",
       "      <td>Rs. 6990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men Charged Bandit 6 Running</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Cell Fraction Fade Running</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR ZOOM Running</td>\n",
       "      <td>Rs. 8771Rs. 13495(35% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Slip-On Sneakers</td>\n",
       "      <td>Rs. 9490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Flatform Sneakers</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Driving Shoes</td>\n",
       "      <td>Rs. 9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VIONIC</td>\n",
       "      <td>Men Textured Sneakers</td>\n",
       "      <td>Rs. 7039Rs. 10999(36% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand             Product Description                        Price\n",
       "0           ALDO               Men Driving Shoes                    Rs. 11999\n",
       "1           Nike   LEBRON XVIII Basketball Shoes  Rs. 11436Rs. 17595(35% OFF)\n",
       "2      J.FONTINI    Men Textured Leather Loafers                     Rs. 6990\n",
       "3   UNDER ARMOUR    Men Charged Bandit 6 Running                     Rs. 8999\n",
       "4           Puma  Men Cell Fraction Fade Running                     Rs. 6999\n",
       "..           ...                             ...                          ...\n",
       "95          Nike          Women AIR ZOOM Running   Rs. 8771Rs. 13495(35% OFF)\n",
       "96          Geox    Men Leather Slip-On Sneakers                     Rs. 9490\n",
       "97          Geox         Women Flatform Sneakers                     Rs. 9999\n",
       "98          Geox       Men Leather Driving Shoes                     Rs. 9990\n",
       "99        VIONIC           Men Textured Sneakers   Rs. 7039Rs. 10999(36% OFF)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Dataframe\n",
    "df= pd.DataFrame()\n",
    "\n",
    "df['Brand'] = brand\n",
    "df['Product Description'] = desc\n",
    "df['Price'] = price\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10: Go to webpage https://www.amazon.in/ and scrape first 10 laptops data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting url\n",
    "page9  =  driver.get(' https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill up search box \n",
    "search = driver.find_element_by_id('twotabsearchtextbox')\n",
    "search.send_keys('Laptop')\n",
    "time.sleep(3)\n",
    "#click button\n",
    "btn = driver.find_element_by_id('nav-search-submit-button')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#filter cpu to intel i7\n",
    "filter_cpu1 = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div/div[2]/div/div[3]/span/div[1]/span/div/div/div[6]/ul[1]/li[26]/span/a/div/label/i').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter cpu to intel i9\n",
    "filter_cpu2 = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div/div[2]/div/div[3]/span/div[1]/span/div/div/div[6]/ul[1]/li[28]/span/a/div/label/i').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []#empty list\n",
    "price = []#empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find elments\n",
    "titles = driver.find_elements_by_xpath('//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\"]')\n",
    "pprice = driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "\n",
    "for i in titles:\n",
    "    title.append(i.text) #scrape product titles\n",
    "time.sleep(2)\n",
    "\n",
    "for i in pprice:\n",
    "    price.append(i.text) #scrape product price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratinglinks = []#empty list\n",
    "\n",
    "ratings_link = driver.find_elements_by_xpath('//a[@class=\"a-link-normal a-text-normal\"]')\n",
    "time.sleep(3)\n",
    "\n",
    "for i in ratings_link:#scraping ratings list\n",
    "    ratinglinks.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = []#empty list\n",
    "\n",
    "for i in ratinglinks[:10]:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    try: \n",
    "        ratings = driver.find_element_by_xpath('//span[@class=\"a-size-medium a-color-base\"]')\n",
    "        rating.append(ratings.text)#scraping rating of the products\n",
    "    except:\n",
    "        rating.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo Legion 7 10th Gen Intel Core i7 15.6 in...</td>\n",
       "      <td>2.9 out of 5</td>\n",
       "      <td>1,80,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6\" (39.62 cms) FH...</td>\n",
       "      <td>4.5 out of 5</td>\n",
       "      <td>1,07,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>59,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSI GF65 Thin, Intel i7-10750H, 15.6\" FHD (39....</td>\n",
       "      <td>3.6 out of 5</td>\n",
       "      <td>81,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS TUF Gaming F15 (2020), 15.6-inch (39.62 c...</td>\n",
       "      <td>4 out of 5</td>\n",
       "      <td>71,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>3.8 out of 5</td>\n",
       "      <td>34,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td>4 out of 5</td>\n",
       "      <td>90,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dell Inspiron 5502 15.6\" FHD AG Display Laptop...</td>\n",
       "      <td>5 out of 5</td>\n",
       "      <td>85,890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) Lenovo Intel Core i7-4th Gen 14 Inch...</td>\n",
       "      <td>-</td>\n",
       "      <td>44,999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Rating     Price\n",
       "0  Lenovo Legion 7 10th Gen Intel Core i7 15.6 in...  2.9 out of 5  1,80,990\n",
       "1  ASUS TUF Dash F15 (2021), 15.6\" (39.62 cms) FH...  4.5 out of 5  1,07,990\n",
       "2  Mi Notebook Horizon Edition 14 Intel Core i7-1...  4.4 out of 5    59,490\n",
       "3  HP Pavilion (2021) Thin & Light 11th Gen Core ...  4.3 out of 5    84,990\n",
       "4  MSI GF65 Thin, Intel i7-10750H, 15.6\" FHD (39....  3.6 out of 5    81,990\n",
       "5  ASUS TUF Gaming F15 (2020), 15.6-inch (39.62 c...    4 out of 5    71,990\n",
       "6  Life Digital Laptop 15.6-inch (39.62 cms) (Int...  3.8 out of 5    34,990\n",
       "7  Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...    4 out of 5    90,490\n",
       "8  Dell Inspiron 5502 15.6\" FHD AG Display Laptop...    5 out of 5    85,890\n",
       "9  (Renewed) Lenovo Intel Core i7-4th Gen 14 Inch...             -    44,999"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Dataframe\n",
    "df = pd.DataFrame()\n",
    "df['Title'] = title[:10]\n",
    "df['Rating'] = rating[:10]\n",
    "df['Price'] = price[:10]\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
